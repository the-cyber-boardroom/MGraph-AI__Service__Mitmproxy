# Advanced HTML Content Transformation Strategies (Mitmproxy Pipeline)

**Introduction:**

The next phase of the mitmproxy-based HTML content transformation
project focuses on *UI-level modifications* to webpage content based on
semantic sentiment classification. Building on the existing architecture
-- which includes a mitmproxy intercept, an HTML Service for text
hashing, and a Semantic Text Service for classification -- we will
introduce new transformation modes to alter or hide HTML text nodes (and
related DOM elements) according to their sentiment. The current pipeline
already supports cookie-controlled filtering and deterministic text
hashing for classification. Phase¬†2 will extend this with *modular,
configurable transformations* like masking, emoji replacement, content
removal, etc., and consider grouping (clustering) multiple text spans
and even images for collective handling. All transformations will be
**deterministic** (for testability) and toggled via a cookie or admin
UI, ensuring we can seamlessly A/B test modes without affecting normal
browsing.

## 1. Transformation Strategies and Modes

We propose at least five core transformation modes (with several novel
variants) to encode or conceal text content. Each mode replaces text
**only if** it meets the sentiment filter criterion (e.g. highly
negative sentiment), unless otherwise noted. These transformations
preserve overall HTML structure and punctuation, ensuring the page
layout remains intact. The modes can be configured and combined for
different use cases:

-   **a. Character Masking ("XXX" Mode):** Replace each alphabetic or
    numeric character with a fixed symbol (like "x"), while preserving
    spaces and punctuation. This acts like a privacy mask that hides
    actual words but retains text length and structure (so the content's
    shape is visible, but not readable). For example,


-   Original: "Terrible product! Awful service."
        Masked:   "xxxxxxxx xxxxxxx! Axxxx xxxxxxx."

    Here all letters are replaced by "x" (uppercase/lowercase
    distinction is lost), punctuation ("!") and spaces are unchanged.
    The transformation ensures consistent length and word breaks,
    maintaining the original text's layout. This mode is useful for
    privacy filtering -- it redacts content while giving a sense of
    sentence structure. (It's currently implemented as `mitm-mode=xxx`
    in the proxy.)


-   **b. Length-Based Grouping ("ABCDE" Mode):** Group text by length
    and replace characters with placeholder letters that indicate the
    size category. In the current prototype, five letter groups (a, b,
    c, d, e) represent progressively longer text segments. All
    characters in a given text node are replaced by *the same letter*
    repeated to the original length. For example:


-   "Hi" (2 chars)    ‚Üí "aa"
        "Hello" (5 chars) ‚Üí "bbbbb"
        "Welcome" (7 chars) ‚Üí "ccccccc"

    In this scheme, very short texts map to "a", slightly longer to "b",
    etc., up through "e" for the longest texts. The exact length
    thresholds can be tuned (e.g. 1--2 chars = 'a', 3--5 = 'b', 6--8 =
    'c', 9--11 = 'd', 12+ = 'e'). This grouping abstracts away actual
    content but **preserves the visual span** of text elements, helping
    reveal page structure without readable text. Developers can quickly
    see layout (short vs. long headings, paragraphs length) while
    sensitive content remains obscured. (This mode was prototyped as
    `mitm-mode=abcde-by-size`.)


-   **c. Emoji-Based Sentiment Encoding:** Replace text with an
    **emoji** that represents its sentiment class. The idea is to
    compress an entire text span into a single symbol conveying tone
    (positive, negative, etc.). For example, a highly negative sentence
    could be replaced with a frowning or angry face emoji (e.g. üò†), a
    positive statement with a smiley (üòä), and a neutral text with a
    neutral face (üòê). One mapping could be:\
    -- Negative sentiment ‚Üí üò† (angry face)\
    -- Very negative (score extreme) ‚Üí üî¥ or ‚òπÔ∏è (red circle or sad
    face)\
    -- Positive ‚Üí üôÇ (smiling face)\
    -- Very positive ‚Üí üòÉ (grinning face)\
    -- Neutral/mixed ‚Üí üòê or ü§î (neutral or thinking face)\
    For instance, **"This product is awful"** might transform to just
    **"üò†"**. If a text span contains mixed sentiments, we might choose
    an ambiguous emoji (üòï). This mode does *not preserve text length*
    (one emoji replaces the whole span), but it gives a quick visual cue
    of sentiment. It's essentially a visualization of sentiment analysis
    -- instead of words, the reader sees an emotional "rating" via
    emoji. The emoji set can be configured; for example, an admin could
    choose a different emoji scale or even custom icons. This approach
    allows an at-a-glance understanding of content tone while fully
    hiding the actual words. (It could be combined with clustering --
    e.g. one emoji per paragraph's overall sentiment.) **Note:** This
    mode requires careful mapping from sentiment scores to discrete
    emojis; for initial implementation we can map the dominant sentiment
    category from the classifier to a corresponding emoji.

-   **d. Blank-Out Removal:** Simply remove the text entirely, showing
    nothing in its place (or an optional subtle placeholder). In HTML
    terms, the text node's content is set to an empty string (or the
    element could be hidden). For example, **"Terrible product"** would
    become **""** (empty). This is the most aggressive filter -- the
    user sees no hint of the original message. It can be useful for
    *content removal*, where any text matching the filter (e.g.
    extremely negative or toxic content) is deemed better omitted. An
    optional variant is to replace the text with an innocuous
    placeholder like "\[removed\]" or a zero-width space so that the
    layout isn't disturbed. However, fully blanking will collapse inline
    content (e.g. "I think \[blank\]" would result in double spaces). In
    block contexts (paragraphs, list items), a removed text might leave
    an empty gap. We might mitigate layout issues by inserting an HTML
    comment or a non-breaking space of equal length. For example, to
    preserve spacing we could replace each character with a space or use
    a CSS trick (like setting visibility: hidden on the text element to
    keep its size). In any case, **no readable characters remain**. This
    mode is essentially a "censorship" approach -- it prevents
    potentially harmful text from being seen at all.

-   **e. Text Hashing (Deterministic Fingerprint):** Replace each text
    with a hash code or an encoded token that uniquely represents the
    original content. For instance, *"Great product"* might become a
    string like *"9f2a5c..."* (an MD5/SHA digest or a short alphanumeric
    ID). The implementation in the current system uses a consistent hash
    mapping: the same input text always yields the same hash output.
    This mode is **not user-friendly** (the output is gibberish from a
    reader's perspective), but it is extremely useful for debugging and
    analysis. It allows developers to identify repeated text segments
    across pages (since identical phrases hash to the same code) and
    verify that transformations are deterministic. For example:


-   Original: "Hello, World!"
        Hashed:   "5eb63bbbe01eeed093cb22bb8f5acdc3"

    (Here the hash looks like an MD5 digest.) Shorter hashes or
    human-readable tokens can also be used. The key property is
    *consistency*: if "Hello, World!" appears multiple times in a site,
    each occurrence is replaced by the same hash string, making it clear
    they were identical originally. This mode is often run with the
    **Text Hash Engine** for classification, which doesn't do real
    sentiment analysis but ensures stable outputs. In effect, *Text
    Hashing mode* provides a reversible mapping for those with access to
    the hash dictionary, and acts as a sanity check for the pipeline (no
    content leaked, but transformations can be verified by comparing
    hashes).


-   **f. *Additional Novel Transformations:*** In addition to the above
    core modes, we propose a few creative strategies to explore:

**‚Ä¢ CSS Blurring of Text:** Instead of replacing characters, we can blur
the text on the page so it's unreadable unless un-blurred (similar to a
spoiler or sensitive content overlay). This can be achieved by applying
a CSS rule such as making the text color transparent with a heavy
text-shadow, or using the CSS `filter: blur(px)` on the text element.
For example, a `<span>` containing negative text could get a class
`blur-text` which in CSS is defined to blur the text (e.g.
`blur-text { color: transparent; text-shadow: 0 0 5px #000; }` which
produces a 5px blur shadow). Visually, the text becomes a smudged line,
maintaining its general width but undecipherable. This mode is
reversible in the sense that if someone were to remove the CSS (e.g.
using dev tools or copy-pasting the text, or if a determined user tries
to apply image sharpening techniques), the underlying text could be
revealed. For stronger protection, we could combine this with overlaying
a solid background or mask before blurring. As a user-facing feature,
blurred text can signal that content is hidden (similar to how some
messaging apps blur sensitive images by default until clicked). This
could be paired with a UI interaction: e.g. if the user clicks or
toggles a setting, the blur is removed (revealing the text) -- though
implementing that requires client-side support beyond the scope of
mitmproxy injection. Initially, we'll treat blur as a one-way transform
for demonstration. It's a less blunt tool than blanking out text; the
reader sees that *something* is there and roughly how long it is, but
not the details. (Consider combining with a brief placeholder label like
"\[blurred\]" for accessibility if needed.)

**‚Ä¢ ROT13 or Cipher Text Encoding:** Another transformation is to
**encode text via a simple cipher**, such as ROT13 (rotate letters by 13
places) or a Caesar shift. For example, "Bad service" becomes "One
freivpr" under ROT13. This looks like gibberish, but it's reversible if
one knows the method. The purpose is mainly demonstrative -- it obscures
content from casual view while indicating that it's encoded rather than
random. Unlike hashing, ROT13 preserves word length and even some letter
patterns (though not as clearly as masking). It's not secure (trivially
decodable), but it's a classic method used for hiding spoilers in
forums, etc. This could be a toggle mode for internal testing: e.g.
`mitm-mode=rot13-negative` would scramble negative text in a reversible
way. We might not use this in production for users, but it's a low-cost
addition to test the flexibility of the pipeline (and to confirm that
our system can output non-ASCII characters correctly if we use any). A
variant would be a *substitution cipher with a secret key*, or even
Base64 encoding of the text, if we wanted to hide content behind a
reversible transformation that's not human-readable. These aren't
typical end-user features, but serve as additional tools in our
transformation toolkit for specific needs (e.g. sharing a page state
with another developer who can decode the text).

**‚Ä¢ Content Replacement with Notice:** Instead of leaving removed
content blank, we can insert a **placeholder label or icon** to indicate
that something was removed or filtered. For example, replace the text
with a tag like "\[Content removed\]" or an icon like üö´ or ‚ö†Ô∏è. This
approach is similar to how some forums show "\[comment deleted\]" in
place of a removed comment. In our context, if a sentence is classified
as very negative and we choose to hide it, we might replace it with a
translucent "‚Äï" (em dash) or a small badge indicating content was
filtered. This gives users a hint that content was deliberately hidden
(which might be important in certain UI contexts so the user doesn't
just think the page is glitchy or missing text). For instance:

    Original: "The following review contains strong language."
    Removed:  "[Negative content hidden]"

or simply an emoji like ‚ùå in place of the text. This mode is useful if
we want to be transparent about filtering. It requires carefully
choosing the placeholder so as not to clutter the UI. We can style
placeholders (e.g. grey italic text in brackets) to be subtle. Like
blank-out, this mode doesn't preserve original content, but it occupies
similar space (though not exact length). We might consider making the
placeholder roughly the same length as the original (e.g. by padding
with dots) to preserve layout, but that could be overkill. A simpler
variant: a small icon that user can hover for "This text was hidden due
to negative sentiment." This again is beyond static HTML transformation
(would need a tooltip script or at least a title attribute). Initially,
a static notice text could suffice to illustrate the idea.

Each of these modes can be **modularly toggled**. The transformation
logic will ensure that *non-filtered text remains unchanged*, and only
the targeted text nodes are altered according to the active mode. The
modes like masking, grouping, hashing have already proven viable in the
architecture (they exist in v0.8.1), and new ones like emoji or blur
will be built on the same principles (replacing or styling text via the
proxy). We will implement these such that they do not break the HTML
structure -- e.g. replacing text content but not removing the actual
elements (except in blank-out mode where content is empty, the element
still exists). Punctuation and whitespace should be preserved by all
modes (except full removal) to maintain readability of unaffected parts.

To summarize the transformation modes, the table below lists the key
behaviors:

  ---------------------------------------------------------------------------
  **Mode**                **Description**         **Example Output**
  ----------------------- ----------------------- ---------------------------
  **Mask (XXX)**          Redact letters/numbers  `"Hate it!" ‚Üí "xxxx xx!"`
                          with "x"; preserves     (letters hidden)
                          punctuation/spacing.    

  **Length Grouping**     Replace text with       `"Bad"` (3 chars) ‚Üí `"bbb"`
                          repeated letter         (if 3--5='b')
                          representing length     
                          group.                  

  **Emoji Encode**        Replace text with a     `"Amazing!"` (positive) ‚Üí
                          sentiment emoji (loses  `üôÇ`
                          length).                

  **Blank Remove**        Omit text entirely (or  `"Awful service"` ‚Üí `""`
                          insert nothing/space).  (gone)

  **Hashing**             Replace text with       `"Hi"` ‚Üí `"49f68a5..."`
                          deterministic hash      (same every time)
                          code.                   

  **Blur Text**           Apply CSS blur to text  `"Sensitive"` ‚Üí blurred
                          (text remains in DOM    (fuzzy text)
                          but unreadable).        

  **ROT13 (Cipher)**      Encode text with ROT13  `"Bad"` ‚Üí `"Onq"` (ROT13)
                          or similar              
                          substitution.           

  **Notice Replace**      Replace text with       `"Rude comment"` ‚Üí
                          placeholder label or    `"[hidden]"`
                          icon.                   
  ---------------------------------------------------------------------------

*(The above are illustrative; actual outputs like hash strings will
vary. Modes can be combined or extended as needed.)*

## 2. Clustering Strategies for Text Spans

In Phase¬†2 we also introduce **clustering** of text nodes -- grouping
multiple nearby or related text elements -- to enable transformations at
a higher scope than individual words or nodes. Clustering helps treat a
set of contiguous or semantically related text as one unit, so that a
transformation can be applied holistically (e.g. hide an entire sentence
or paragraph if it's overall negative, rather than masking just a few
words). We will consider clustering along three main axes:
**proximity**, **DOM structure hierarchy**, and **sentiment
similarity**.

-   **a. Proximity-Based Clustering:** Group text spans that are close
    together in the rendered content. For example, if two or more
    flagged (negative) words occur in the same sentence or adjacent
    sentences, they can be merged into one cluster. The idea is to avoid
    choppy output where, say, three negative words in a row get
    individually replaced by "xxx" or emojis, possibly leaving awkward
    gaps or partial context. Instead, we cluster them and apply one
    unified transformation. Proximity can be defined in terms of
    character distance or node distance. For instance, two flagged words
    separated by only a short neutral phrase could be considered one
    cluster. **Example:** Original text: *"This is \[terrible\] and
    \[horrific\] service."* (brackets indicating negative words). Rather
    than masking each word separately ("This is xxxx and xxxxxxx
    service"), we treat the phrase "terrible and horrific" as one
    cluster because the words are adjacent in the sentence. A
    cluster-level transformation might then replace the entire phrase
    with a single placeholder, e.g. "This is \[‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†\] service." or
    "This is üò° service." (one emoji covering the combined sentiment of
    the phrase). Proximity clustering ensures a more *natural-looking
    result* by not over-segmenting a continuous negative expression.

-   **b. DOM Structure-Based Clustering:** Group text by their position
    in the HTML DOM tree. Text nodes under the same parent element or in
    the same logical section can form a cluster. For example, if an
    entire `<p>` paragraph or a `<div>` section contains multiple
    negative sentences, we might cluster at the paragraph level.
    Similarly, multiple list items (`<li>`) inside the same `<ul>` menu
    that are classified as negative could form one cluster representing
    that menu section. The rationale is that *structural groupings
    provide context:* if a container element has predominantly negative
    content, we might prefer to transform or hide the container as a
    whole, rather than piecewise. **Example:** Suppose a product review
    consists of a title and a body:
    `<div class="review"><h3>Title</h3><p>Very bad experience. Nothing was good.</p></div>`.
    If both sentences in the `<p>` are negative, structure-based
    clustering would treat the entire paragraph (or even the whole
    review div) as one cluster. We could then replace the **entire
    paragraph text** with a single summary transformation (e.g.
    "xxxxxx xxxxxxxxxx. xxxxxxx xxx xxxxx." masked all at once, or just
    "\[Negative review\]"). This approach can also be hierarchical: we
    might cluster at different levels (sentence vs. paragraph vs.
    section) depending on configuration. By using the DOM, we leverage
    existing content grouping (paragraphs, list groups, article
    sections) as natural cluster boundaries.

-   **c. Sentiment Similarity Clustering:** Group text nodes that have
    similar sentiment classification results, even if they are not
    adjacent, to ensure consistent transformation. For instance, if a
    page has several short negative snippets scattered (like multiple
    negative tags or labels), we might cluster them conceptually to
    apply the same transformation style to all. However, more
    practically, sentiment similarity is often used in conjunction with
    proximity or DOM context: e.g. cluster contiguous negative elements,
    as discussed. Another angle is clustering by **sentiment intensity**
    -- grouping text that falls above a certain negativity threshold vs.
    those that are borderline. If we had gradations (like moderately
    negative vs extremely negative), we might cluster extremely negative
    items together to possibly apply a more drastic transformation (like
    complete removal) to that cluster, while only masking moderate
    negatives. For now, since our primary categories are the ones given
    by the classifier (positive/negative/neutral/mixed), similarity
    clustering essentially means grouping all negatives in a local
    region or all positives in a region. This ensures uniform handling
    (e.g. don't half-remove and half-mask in one sentence -- treat the
    whole sentiment uniformly).

**Using Clusters for Scope Control:** Once clusters are identified (via
one or a combination of the above methods), the system can apply
transformations at *different scopes*: at the level of a phrase, a full
sentence, a paragraph, or an entire section of the page. This is
powerful for customizing how much context is filtered out. Some use
cases and examples:

-   **Paragraph-level filtering:** If most of a paragraph's content is
    classified negative, the system can hide or transform the *whole
    paragraph* as a block. For example, an entire user comment that's
    toxic might be replaced with "\[Comment removed\]" instead of
    showing any part of it. In an ASCII mockup:\
    **Before:**


-   <p>Customer Review: This place is awful. The food was cold and the staff were rude.</p>

    (Assume this paragraph is 100% negative.)\
    **After (clustered at paragraph):**

        <p>[Negative content hidden]</p>

    Here, rather than masking each sentence or word, the whole `<p>` is
    treated as one cluster and replaced by a notice. This provides a
    cleaner result in the UI -- an entire paragraph blanked or replaced,
    which might appear as just an empty space or a single "\[removed\]"
    line, avoiding partial redactions that still leave some negative
    context visible.


-   **Section or Menu-level filtering:** Consider a navigation menu or a
    list of items where several entries are flagged (say they contain
    negative or sensitive labels). Using DOM clustering, we could
    operate at the `<ul>` level or `<section>` level. For instance, a
    `<section>` element that groups a bunch of content (like a forum
    thread) might be hidden entirely if the majority of its sub-content
    is flagged. An example in pseudo-UI:\
    **Before (menu):**


-   Menu:
         1. Home
         2. Nice Products
         3. Terrible Products (flagged negative)
         4. Contact Us

    If item 3 "Terrible Products" is considered a negative phrase, one
    approach is to just transform that text (e.g. "XXXXXXX Products").
    But if we cluster at the menu level and find that maybe multiple
    items are problematic (imagine items 3 and 4 were negative for some
    reason), we might hide the entire menu section.\
    **After (if clustering whole menu):**

        Menu:
         [Some items were removed]

    Or possibly remove the menu entirely. This might be extreme; more
    realistically, we'd handle each menu item individually. However, for
    something like a **section** of an article -- say a section with a
    negative headline and negative content -- one could collapse the
    entire section with a placeholder "Section removed due to content".
    The clustering logic would identify that the headline and content
    are both negative and then treat the `<section>` container as the
    cluster to transform.


-   **Sentence-level grouping:** Within a paragraph, we could cluster by
    sentence. If a sentence contains any negative parts above threshold,
    we decide to transform the entire sentence as one unit (for example,
    blur the whole sentence or mask it entirely), rather than only the
    specific flagged phrase. This ensures the sentence's meaning is
    fully obfuscated, avoiding a weird mix of hidden and visible words.
    E.g., original: "The product was \[horrible\], it made me \[sick\].
    I would never recommend it." If we cluster by sentence, the entire
    first sentence (which contains those two negative segments) could be
    masked out completely (e.g. "XXXXXXXXXXXX.") while leaving the
    second sentence (which is also negative in tone, actually) either
    separate or also removed depending on classification. This yields a
    more uniform filtering -- either the whole sentence passes or gets
    filtered, mimicking how content warnings often work at sentence or
    paragraph granularity.

**Clustering Implementation:** We will likely implement clustering logic
in the HTML transformation phase (after obtaining classification for
individual text nodes). The algorithm could be:

1.  **Mark individual nodes:** First, classify each text node and mark
    those that meet the negative (or chosen sentiment) criteria as
    "flagged". We get a set of flagged nodes with their DOM positions
    and sentiment scores.

2.  **Group into clusters:** Then, traverse the DOM structure to group
    flagged nodes:

3.  If using proximity: merge flagged nodes that are adjacent or
    separated only by short neutral nodes.

4.  If using structure: look at parent elements -- e.g. if a parent has
    multiple children flagged, mark the parent as a cluster container.
    Also, siblings in a list could form a cluster if consecutive.

5.  If using similarity: possibly group all flagged nodes of the same
    sentiment category in a region, etc. Each cluster can be represented
    by either a representative node (like the parent element) or a range
    of text nodes.

6.  **Apply cluster-level rules:** Determine the transformation for each
    cluster. For a cluster that corresponds to a parent element (like a
    `<div>` or `<p>`), we might decide to *override* individual
    transformations and instead apply one big change to that parent.
    E.g., set the parent's textContent to an emoji or add a CSS class to
    blur the entire block. For clusters that are inline (like multiple
    words in a sentence), we might wrap them in a single `<span>` and
    replace that span with a placeholder text or emoji.

7.  **Avoid double-transforming:** If a cluster transformation is
    applied at a parent level, we ensure the child nodes aren't
    separately transformed to something contradictory. For example, if
    we decide to remove an entire `<div>` due to clustering, we wouldn't
    also insert masked text inside it -- we'd drop the children
    entirely. The system will include logic to handle these exclusions
    (perhaps by marking child nodes as "handled by cluster" to skip them
    in individual transformation step).

By clustering, we can **scale the scope of transformations** from
fine-grained (word-level) to coarse-grained (section-level) depending on
need. This flexibility is controlled by configuration: for instance, an
admin could set *cluster_mode = none* (no clustering, just per text
node), or *cluster_mode = paragraph* (group by block elements), etc. We
might provide multiple cluster strategy options that can be toggled
similarly to transformation modes.

In practice, we'll likely start with a conservative clustering approach
-- e.g. grouping contiguous flagged text in the same paragraph -- to
ensure we don't accidentally hide too much context. Then we can
experiment with broader scopes (like whole paragraph removal) behind a
configuration flag. The goal is to explore how cluster-based transforms
improve (or possibly degrade) the user experience compared to naive
word-by-word filtering.

## 3. Image Association & Transformation

Text is not the only content on a page -- images often accompany or
illustrate textual content. In Phase¬†2, we will explore ways to handle
**images that are in proximity to negative or flagged text**. The
reasoning is that if a text is deemed harmful or sensitive (e.g. a
negative/hate comment), any image directly associated with it might also
be contextually undesirable to show (the image could be offensive or
could reinforce the negative content). Even if the image itself is
benign, hiding or blurring it can emphasize that the entire content
block is under moderation.

**Detection of Associated Images:** We define "associated" images as
those that are near flagged text in the DOM. This could mean: - The
image is within the same container element as the text (e.g. an `<img>`
inside a `<div>` where a negative paragraph also resides). - The image
immediately precedes or follows a flagged text node (like an avatar or
an inline emoji image next to a toxic comment). - The image has an **alt
text or caption** that was classified as negative. In such a case, even
if the image content is unknown, the text describing it is negative,
implying the image might be something negative as well. - The image is
part of a content unit that is primarily negative. For instance, a news
article with a negative headline and an image header -- one might blur
the image along with filtering the headline if the article is deemed
disturbing.

The DOM structure can help: if a `<figure>` contains an `<img>` and a
`<figcaption>` (caption text), and the caption text is flagged, we can
consider the image flagged too by association. Or if an `<article>`
contains multiple paragraphs and an image, and if we decide to hide that
article cluster, we should also hide/blur the image within it.

**Image Transformation Techniques:** Once an image is flagged by
association, we have a few possible actions: - **Blur the image:** Apply
a Gaussian blur filter via CSS to the `<img>` element. This is
straightforward: for example, adding `style="filter: blur(8px);"` to the
`<img>` tag will render it blurred. The level of blur can be tuned (e.g.
5px vs 10px radius) depending on how obscured we want it. A blurred
image will still occupy the same space and roughly the same colors, but
details are hidden. This is similar to how sensitive images are handled
on social media (with a blur or pixelation that the user can click
through -- though in our case, we might not implement the
click-to-reveal unless we add some client-side script). An ASCII
illustration:\
**Before:** `[Image: üë®‚Äçüç≥ (chef photo)] "The meal was terrible."`\
**After (image blurred, text masked):**
`[Image: ~~blurred~~] "XXXX XXX ********."`\
Here the image of the chef (assuming it was next to a negative review)
is blurred out. The alt text or caption, if any (here a caption "The
meal was terrible."), is also transformed by the text filter. The result
is the image is still present but indistinct, indicating content is
hidden.

-   **Replace the image:** Swap the image source with a placeholder
    image or icon. For instance, an `<img src="graphic.jpg">` could be
    replaced with `<img src="placeholder.png">` where *placeholder.png*
    is a generic "content removed" graphic or just a solid color.
    Alternatively, we could remove the `src` and use a CSS background
    color to blank it. Replacing might be safer if we truly do not want
    the original image data to load (though with mitmproxy we can also
    prevent loading by rewriting the response or setting the image to
    something like a data URI). For example: if an article had an
    offensive image, we could inject an image of a stop sign or a
    blurred version. Even simpler, we can set an inline style to display
    a colored rectangle of the same width/height as the image (mitmproxy
    can compute dimensions if the HTML includes them or after load with
    some script, but at least preserving the container size might
    require knowing the image size; as a first step, just not altering
    the `<img>` element's box will preserve layout). Replacing with a
    small icon:\
    **Before:** `<img src="violent_scene.jpg" alt="Violent scene">`\
    **After:**
    `<img src="hidden.png" alt="[image removed]" style="width:300px; height:200px;">`\
    (Assuming `hidden.png` is a neutral grey image or an icon indicating
    removal.) The alt text could also be changed to \"\[image
    removed\]\" to clarify for screen readers. This method completely
    hides the original content of the image.

-   **Overlay or annotate the image:** Another approach is to keep the
    image but add an overlay element (like a semi-transparent black
    layer or a warning icon on top of it). This can be done by wrapping
    the image in a `<div>` and absolutely positioning an overlay, or
    simpler, by using CSS `::after` pseudo-element on the image's parent
    to display a message. For ASCII representation: imagine an image
    with a big \"üö´\" symbol over it. The HTML might be transformed to:


-   <div class="image-block" style="position: relative; display: inline-block;">
          <img src="example.jpg" style="filter: blur(5px);">
          <div class="overlay" style="position: absolute; top:0; left:0; 
                       width:100%; height:100%; background: rgba(0,0,0,0.5);
                       color: white; display:flex; align-items:center; justify-content:center;
                       font-size: 2em;">
              &#128683;
          </div>
        </div>

    This would show the image blurred and a white \"üö´ (no entry sign)\"
    centered over a semi-transparent dark overlay. While effective, this
    is somewhat heavy on HTML/CSS for an automated proxy transformation.
    It might be beyond scope to inject such complex structure purely via
    mitmproxy text rewriting (though it's possible). For our design, we
    note it as an option for future UI polish.

**DOM Examples and Wireframes:** To illustrate, consider a **tweet-style
post** with text and an image:

    <div class="post">
      <p>I hate this product so much!</p>
      <img src="product.jpg" alt="Picture of the product">
    </div>

Let's say the text is classified as highly negative. A transformation
with image association could yield:

-   *Mask text + blur image:*


-   <div class="post negative-cluster">
          <p>I xxxx this product xx xxxx!</p>
          <img src="product.jpg" style="filter: blur(8px);" alt="Picture (blurred)">
        </div>

    **Rendered (ASCII wireframe):**

        [Post]
        "I xxxx this product xx xxxx!"
        [Image: (blurred product picture)]

    The `<div>` might be tagged with a class `negative-cluster` for
    styling (e.g. we could also add a red border around the whole post
    to indicate it's flagged). The text is masked and the image visibly
    blurred. The user can see something is there but not details.


-   *Remove text + remove image:*

    We decide to hide the entire content. We could then output:


-   <div class="post negative-cluster">
          <p>[content removed]</p>
          <!-- image removed -->
        </div>

    **Rendered:**

        [Post]
        [content removed]

    The image tag is actually stripped out in this scenario (or we could
    leave an empty `<img style="display:none">`). The paragraph is
    replaced with a notice. This is a cluster-level removal covering
    both text and media.


-   *Emoji text + replace image:*

    Another scenario: replace the text with an emoji and the image with
    a placeholder:


-   <div class="post negative-cluster">
          <p>üò°</p>
          <img src="placeholder.png" alt="[image hidden]" width="500" height="300">
        </div>

    **Rendered:**

        [Post]
        üò°
        [Image: hidden]

    This makes it obvious that the post was angry (from the emoji) but
    the actual content and image are withheld.

The above examples demonstrate varying levels of aggressiveness. We will
make these behaviors **configurable**. For instance, one site or
use-case might prefer just blurring images (so user can decide if they
want to discern it), whereas another might require full removal for
legal or safety reasons.

From an implementation perspective, detecting images near flagged text
requires parsing the DOM structure we get from the HTML Service. The
`html_dict` representation from the HTML Service will list image tags
and their positions relative to text nodes. If a text node is flagged
and its sibling or parent is an `<img>`, we can mark that `<img>` for
transformation. Alternatively, we can do a second pass: after marking
clusters of text, for each cluster that spans an element containing
images, mark those images.

We should note a **safety consideration**: simply blurring an image
might not be enough if the image itself contains text (like a
screenshot) or identifiable information -- blur can sometimes be
partially reversed or at least the gist seen. For stronger redaction,
replacing or overlaying is safer. In our context (sentiment filtering),
the images likely illustrate the text but might not themselves contain
text that needs hiding. Still, it\'s worth mentioning that blurring is a
*visual deterrent* but not a cryptographic removal. Tools exist that can
partially deblur images, so if absolute secrecy is needed, a solid fill
or removal is better. We can incorporate a hybrid approach as mentioned
by a commenter: cover the image with a solid overlay and then blur, to
ensure no original pixels can be sampled.

For Phase¬†2, the main goal is to prototype **blurring and basic
replacement** of images via the proxy. We will likely implement a simple
rule: if an image's parent container has any negative text flagged,
append a `style="filter: blur(5px)"` to that `<img>` tag in the output
HTML. This one-line change will demonstrate the concept. Further
enhancements (like choosing blur vs removal via config, or adding
alt-text modifications) can be layered on.

## 4. UI Configuration Model

To manage all these new transformation capabilities, we will extend the
existing **cookie-based configuration** mechanism. Currently, the system
uses a cookie named `mitm-mode` to control the transformation mode and
filter criterion (e.g. `mitm-mode=xxx-negative` to mask negative
text).
We will preserve this approach and expand it to handle the additional
modes, clustering options, and parameters like sentiment threshold and
emoji sets.

**Mode Selection via Cookie:** Each transformation mode can be invoked
by a keyword in the cookie value. For example: -
`mitm-mode=emoji-negative` -- would activate emoji-based encoding for
any text classified as negative (above a default threshold). -
`mitm-mode=blur-negative` -- blur text (and possibly images) for
negative content. - `mitm-mode=remove-negative` -- blank out negative
content. - We could also allow explicit mention of threshold: e.g.
`mitm-mode=xxx-negative-0.5` to mean mask text with negative score \>
0.5. The parsing logic can extract the numeric value as a custom
threshold. - Combining criteria: maybe `mitm-mode=xxx-negative-neutral`
(if one wanted to target both negative and neutral content, though
that's unusual). The config format could allow multiple criteria with
logical OR/AND, but that complicates the cookie string. Alternatively,
we continue to support only one primary criterion via cookie (like the
current scheme of `xxx-negative`, `xxx-hide-positive`, etc. as seen in
documentation).

To illustrate how cookie values map to filtering behavior, here are some
examples: - `mitm-mode=xxx-negative` -- Use masking mode for text;
filter criterion = *negative sentiment above default threshold*. In the
current config, this usually means any text with negative score \> \~0.3
is
masked.
Positive or neutral text remains unchanged. *(Engine default: likely AWS
Comprehend for real sentiment detection.)* -
`mitm-mode=xxx-hide-positive` -- Mask text that is strongly positive.
(This is likely a testing mode; in practice we wouldn't hide positive,
but it exists to verify functionality.) - `mitm-mode=hashes-all` -- We
could define that as "replace all text with hashes (no sentiment
filter)". Internally, that would set no criterion filter and
transformation_mode = HASHES, effectively hashing everything. Similarly
`mitm-mode=xxx-all` might mask everything unconditionally (like a full
privacy mode). This could be implemented by either special keywords or
by treating absence of a sentiment qualifier as "no filter, apply to
all". - `mitm-mode=emoji-mixed` -- Replace text with emojis if sentiment
is *mixed* (this could be an experimental mode if we want to catch
content that is ambiguous). - `mitm-mode=blur-negative-0.8` -- Blur any
content that is very negative (score \> 0.8). This high threshold means
only extremely negative text triggers blur, moderate negative might be
left alone. Such granularity helps in tuning.

We likely need to parse the cookie value to extract: 1. the
transformation type (xxx, hashes, abcde, emoji, blur, remove, etc.), 2.
the sentiment target (negative, positive, neutral, mixed or "all"), 3.
optionally a threshold value.

We can maintain a sensible default threshold (say 0.5) if none is
provided. The existing system seems to default to around 0.3 for
negative filtering in examples.

Additionally, we might introduce **separate cookies or flags** for
clustering and image handling, since those are orthogonal to the basic
text transform mode. Possible new cookies or combined parameters: -
`mitm-cluster=on` or `mitm-cluster=paragraph` -- indicating clustering
strategy. For example: - `mitm-cluster=none` (default, treat each text
independently), - `mitm-cluster=phrase` (small proximity clusters), -
`mitm-cluster=block` (cluster by block elements like paragraphs/divs), -
`mitm-cluster=all` (for testing, cluster everything together -- probably
not useful, but could exist). - `mitm-images=blur` or
`mitm-images=remove` -- controlling how associated images are handled
when text is flagged. `mitm-images=off` could mean don't touch images at
all. `mitm-images=blur` would apply blur filter, `mitm-images=hide`
might remove them or replace with placeholder. - Alternatively, we could
fold these into a single cookie string. For example, a very explicit
cookie could be:

    mitm-mode=emoji-negative-0.4_cluster=block_images=blur

This is a bit complex to parse (we'd have to split on underscores or
similar). It might be cleaner to use multiple cookies:

    Set-Cookie: mitm-mode=emoji-negative-0.4; 
    Set-Cookie: mitm-cluster=block; 
    Set-Cookie: mitm-images=blur;

Our proxy already handles parsing "other control cookies", so adding a
couple more should be fine.

**Admin Interface Controls:** The architecture already mentions an Admin
Dashboard for real-time control. We can extend that UI to incorporate
these new options without requiring manual cookie editing: - A dropdown
or radio button list for **Transformation Mode** (Mask, Hash,
Group/ABCDE, Emoji, Remove, Blur, etc.). - A set of checkboxes or
toggles for **Sentiment Criteria** (Negative, Positive, Neutral, Mixed).
Possibly only one active at a time, or multiple combined with an AND/OR
logic. A more user-friendly approach: a multi-select where you can
highlight which sentiment categories to filter, and a slider for
threshold. - A slider or numeric input for **Threshold** (e.g. "Filter
if sentiment score ‚â• X"). This threshold applies to whichever sentiment
category is chosen. In advanced cases with multiple criteria, we'd also
need a logic selector (AND/OR) -- but perhaps the UI can simplify by
only allowing one criterion at a time to avoid confusion, unless an
advanced mode is enabled. - Options for **Clustering**: maybe a dropdown
{None, Light (sentence-level), Medium (paragraph-level), Aggressive
(section-level)} which correspond to increasingly large cluster
scopes. - Option for **Image handling**: {Do nothing, Blur images,
Remove images} near flagged text. - Possibly an **Emoji set selection**
if emoji mode is on: allow choosing between e.g. "face emojis" vs
"colored circles" vs "custom icon set". This is probably overkill for
now, but we can leave it in the design for future extensibility.

All these could be stored as cookie values when the admin toggles them.
The dashboard can simply output a JS snippet to set the cookies and
refresh the page being viewed through the proxy.

**Passing Parameters to the Engine:** On the backend, these UI
selections (or cookie values) need to be translated to the API calls to
the Semantic Text Service. The Semantic service's transformation request
schema already supports specifying the criterion filters (criterion,
above/below, threshold) and the transformation_mode. For example, a JSON
payload internally might look like:

    {
      "hash_mapping": { ... },
      "engine_mode": "AWS_COMPREHEND",
      "criterion_filters": [
        { "criterion": "negative", "filter_mode": "above", "threshold": 0.5 }
      ],
      "logic_operator": "AND",
      "transformation_mode": "EMOJI"
    }

This would instruct: for each text hash, if its negative score \> 0.5,
transform it using the EMOJI mode. The service would then return
transformed text mapping for those that met the filter. For modes like
blur or removal which might not have been originally implemented, we may
either implement them within the Semantic Text Service or handle them in
the post-processing. It's likely easier to handle "blur" and "remove"
outside of the semantic service (since blur is not exactly a text
transformation -- it's a style to apply in HTML). We might use the
semantic service in a classification-only capacity for those modes (i.e.
identify which texts to blur, but not alter the text content via the
service). In such a case, the transformation_mode could be something
like \"PASSTHROUGH\" where the service returns the original text for all
hashes, and we then apply the styling in the HTML step. Or we call the
service with transformation_mode=\"XXX\" just to get the filters applied
(or a new mode \"IDENTITY\" that leaves text unchanged but still
triggers filtering logic).

In any case, the cookie values will be parsed by the proxy and then
translated into the appropriate internal config structure that drives
the pipeline. The pipeline flow from the technical guide can remain the
same: the proxy reads the cookies, decides which mode/filters to apply,
checks cache, and if a transformation is needed, invokes the 3-step
pipeline with parameters reflecting those cookies.

**Combining Modes:** It's worth clarifying how combinations might work.
Generally, we'll use one primary transformation mode at a time for text
content (you wouldn't normally apply two different text transforms
simultaneously on the same text). However, some combinations make
sense: - **Text mode + Image handling:** e.g. Mask text and blur images
together. This is not two text modes, but rather enabling the image blur
option alongside whatever text mode is active. So the cookie config
should allow that (via separate cookie or an extension of the mode
string). - **Text mode + clustering:** again, clustering isn't a
separate visual mode but a strategy on how to apply the text mode. So
this will be an additive option. - It's conceivable to want to mix two
text transformations in different parts of the page, but that would
require more complex rules (e.g. maybe mask negative text but simply
hash positive text -- an odd request, likely unnecessary). We assume one
mode per session for now. - **Cascading transforms:** an interesting
experimental idea could be to apply one transform then another (like
first replace text with hashes, then mask the hashes with Xs -- which
would just result in Xs, so trivial; or first mask, then emoji -- which
doesn't make sense). So practically, no cascade is needed; one mode will
suffice.

Thus, the UI will behave such that selecting one mode will deselect
others. The additional toggles (cluster, images) act as modifiers to
that mode.

To ensure all these are communicated clearly, the **documentation and
the admin UI should display a summary of active settings**. For
instance, the admin panel might show: "**Active Filter:** Mask negative
text (score \> 0.5), cluster by paragraph, blur images = ON." This
summary helps developers quickly understand what is in effect. The
system could also embed a small HTML comment in the transformed page
indicating what mode was applied (for debugging when looking at source).

Finally, using cookies means these settings are per user (or per
session) which is ideal for testing. A developer can open their browser
with the proxy and set a cookie to try a mode, without affecting others.
In a production scenario, one might integrate this with user preferences
or AB tests by issuing specific cookies to certain users.

## 5. Visualization Prototypes (Before/After Examples)

To solidify understanding, here are some prototype visualizations of
content before and after applying various transformation modes and
strategies. These ASCII-style mockups demonstrate the effect of our
system on sample HTML content.

**Example 1: Basic Text Transformations**

*Original snippet:*

    User1: I can't stand this movie. It's absolutely terrible!
    User2: I actually loved it, one of my favorites.

*(Assume the first comment is negative, second is positive.)*

-   **Masking Mode (XXX, negative filter):** Only negative text is
    masked.


-   User1: I can't stand this movie. It's xxxxxxxxxx xxxxxxxxx!
        User2: I actually loved it, one of my favorites.

    *Explanation:* In User1's sentence, the phrase "absolutely
    terrible!" was detected as negative (score high on negative
    sentiment). It gets masked to the same length: "xxxxxxxxxx
    xxxxxxxxx!" (preserving the exclamation point). Neutral parts ("I
    can't stand this movie." might also carry negativity; assuming
    classifier marked the whole sentence as negative, we'd mask all
    except maybe trivial words. Here we showed just the obvious part
    masked). User2's positive comment remains untouched.


-   **Emoji Mode (emoji, negative filter):** Replace negative text with
    an emoji.


-   User1: üò†
        User2: I actually loved it, one of my favorites.

    *Explanation:* The entirety of User1's comment was negative, so we
    replaced the whole text with a single angry-face emoji üò†. The user
    only sees that emoji instead of the text. User2's positive comment
    is unchanged. This conveys "User1 said something angry" without
    showing it.


-   **Blank Removal Mode (remove, negative filter):** Remove negative
    content entirely.


-   User1: [comment removed]
        User2: I actually loved it, one of my favorites.

    *Explanation:* We chose to insert "\[comment removed\]" as a
    placeholder for demonstration (it could also be just nothing after
    "User1:"). The negative comment is fully gone. This might be used in
    a moderation context.


-   **Hash Mode (hashes, all text):** Replace all text with hashes (for
    debugging).


-   User1: 9fbc28d1af3
        User2: c73e6418b92

    *Explanation:* Regardless of sentiment, everything is turned into
    hash strings. "I can't stand this movie. It's absolutely terrible!"
    might hash to "9fbc28d1af3" (random example), and the second comment
    to "c73e6418b92". Identical comments would produce identical hashes
    (here they are different because the comments differ). This verifies
    determinism and that our pipeline processes each text. It's not
    meant for end users, but for us to test or analyze content
    repetition.

**Example 2: Clustering and Scope**

*Original HTML:*

    <div class="review">
      <h4>Review Title: Worst Experience Ever</h4>
      <p>I waited 30 minutes for service. The staff was extremely rude and unprofessional. Never coming back!</p>
    </div>

*(The title and the paragraph are negative in tone.)*

-   **Without clustering (word-level mask):**


-   Review Title: XXXXX Experience Ever
        I waited 30 minutes for service. The staff was extremely xxxx and xxxxxxxxxxxxx. Never coming back!

    *Explanation:* Every individual negative word is masked. "Worst"
    became "XXXXX", "rude" ‚Üí "xxxx", "unprofessional" ‚Üí "xxxxxxxxxxxxx".
    The rest is visible. This leaves behind some readable negative
    context ("Never coming back!" is clearly negative but if that phrase
    wasn't explicitly flagged maybe it slipped through). The title still
    partly reads "Experience Ever" which hints it was a bad experience
    but not entirely hidden. The transformation is very granular here.


-   **With clustering (paragraph-level removal):**


-   [Review removed due to negative content]

    *Explanation:* By clustering, we detected that essentially the whole
    review is negative (title plus paragraph). Instead of masking word
    by word, we remove the entire review `<div>` content and replace it
    with a single notice. The user would just see a blank area or a
    message that the review was removed. This is a cleaner outcome if
    our goal is to shield the user completely from the negative review.


-   **With clustering (section blur):**


-   Review Title: ~~~~~~~~~~~~~~~~
        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

    *Explanation:* Imagine we apply a blur or some block character
    overlay cluster-wide. The title and paragraph are replaced by tilde
    characters (representing blurred lines). This maintains the layout
    (space is occupied by tildes of similar length to original text) but
    nothing readable. If we were actually blurring with CSS, the browser
    would show blurred text in place, which we can't depict well in
    ASCII except by some placeholder pattern as done. The cluster (the
    entire review div) could also have a subtle background highlight to
    indicate it's been moderated.


-   **Cluster by sentence (mixed approach):**


-   Review Title: Worst Experience Ever
        I waited 30 minutes for service. [Sentence hidden] Never coming back!

    *Explanation:* Here we chose to only remove the particularly
    offensive sentence ("The staff was extremely rude and
    unprofessional.") as a cluster, but left the rest. The first
    sentence is factual (30 min wait -- negative situation but maybe not
    flagged as sentiment), the second was clearly negative and got
    hidden entirely, the third "Never coming back!" might be negative
    but short; suppose we left it to show frustration. This is a more
    nuanced filtering -- it required identifying sentence boundaries and
    deciding one was above threshold. The result reads oddly (a sudden
    "\[Sentence hidden\]"), but it illustrates selective removal. In a
    UI, we might not want to show "\[Sentence hidden\]" literally;
    perhaps just a slight gap or nothing at all (which could make the
    paragraph grammatically weird). This shows the kind of decision we
    need to make about whether partial removals are desirable or if it's
    better to escalate to removing the whole paragraph for coherence.

**Example 3: Image Blurring**

*Original HTML:*

    <article class="news">
      <h2>Local Event Turns Chaotic</h2>
      <p>The concert started peacefully but ended in chaos as fights broke out.</p>
      <img src="riot.jpg" alt="Crowd fighting at concert">
      <p>Authorities are investigating the cause of the brawl.</p>
    </article>

*(Assume this news article has a negative tone due to violence.)*

-   **Image blur + text unchanged (for demonstration):**


-   <article class="news negative-cluster">
          <h2>Local Event Turns Chaotic</h2>
          <p>The concert started peacefully but ended in chaos as fights broke out.</p>
          <img src="riot.jpg" style="filter: blur(5px);" alt="Crowd fighting at concert (blurred)">
          <p>Authorities are investigating the cause of the brawl.</p>
        </article>

    **Rendered representation:**

        Local Event Turns Chaotic
        The concert started peacefully but ended in chaos as fights broke out.
        [Image: (blurred scene of a crowd)]
        Authorities are investigating the cause of the brawl.

    *Explanation:* Here we decided to blur the image because the text
    indicates a violent situation (fights). The text itself we left
    as-is (maybe our filter was set to only blur images for violent
    content but not censor text -- just a scenario). The image
    `riot.jpg` would appear as a blurry picture, preventing the user
    from seeing graphic details. The rest of the article remains
    readable. We added a `negative-cluster` class to the article for
    possible styling (e.g. maybe to add a warning icon near the title
    via CSS).


-   **Image removal + text masked:**


-   Local Event Turns Chaotic
        The concert started peacefully but ended in chaos as fights broke out.
        [Image removed]
        Authorities are investigating the cause of the brawl.

    *Explanation:* In this version, the image is completely removed
    (replaced by a "\[Image removed\]" note). Additionally, if we had a
    sentiment filter, maybe we mask some of the intense words in text:
    e.g. "chaos" ‚Üí "xxxxx", "fights broke out" ‚Üí "xxxxx broke out" or
    something, depending on classification. The article is largely
    intact but sensitive details are obscured. The placeholder "\[Image
    removed\]" keeps the reader aware an image was there.


-   **Entire article flagged (cluster removal):**


-   [Content Warning: Negative News Article Hidden]

    *Explanation:* If the entire article is deemed too negative (maybe
    this system is used in a mode to protect users from bad news), we
    might hide the whole `<article>` and show a one-line warning. This
    would remove both text and image. It's an extreme use of
    clustering + removal, effectively collapsing the content. Users
    could be given an option to reveal it (outside the scope of our
    backend, but conceptually). This is akin to content warning banners.

These prototypes show the versatility of the transformation system. We
can mix and match strategies: e.g. cluster at article level but instead
of removing, just blur everything inside (text and images) leaving a
ghosted article that the user could choose to read by removing blur (if
we provided a UI toggle). Or cluster small phrases and replace them with
emojis to give a "sentiment summary" inline.

In ASCII we approximated blur and removal with symbols and notes. In a
real browser, these would be actual styles and elements.

As we implement, we will create a set of test HTML pages with such
content and verify the transformations programmatically, ensuring the
output HTML matches these expectations.

## 6. Testing & Determinism

Testing the transformation pipeline is critical, especially because we
want **fully deterministic results** for given inputs. We have two
powerful features to leverage here: the *text hashing classification
engine* and the deterministic nature of our transformations.

The **Text Hash engine** (one of the Semantic Text Service's modes) will
be our go-to for automated tests. Instead of calling the real ML model
(AWS Comprehend) which is non-deterministic and costs money, we use the
hash-based classifier that produces the same "random" sentiment for a
given text every time. Under the hood, it uses the text's hash as a seed
to generate sentiment scores. This means: - If we feed the same HTML
input multiple times with Text Hash engine, we get the exact same
classification of each text node each time. There's no variability or
external dependency. - We can construct a *reference table* of expected
outputs for known inputs. In fact, the Semantic Text Service
documentation provides deterministic test tables that map certain words
to certain sentiment outputs for the hash engine (often as a convenience
for writing unit tests). - The hash engine runs offline (no external
API), so tests are fast and cost-free.

We will set up various test HTML samples covering different scenarios
(simple paragraph, multiple paragraphs, pages with images, etc.). For
each test case, we specify which mode and filter we are simulating.
Then: 1. **Simulated classification:** We will run the Semantic Text
Service in `text_hash` mode on the test input. This yields a predictable
classification mapping. For example, maybe \"terrible\" always gets a
negative score of 0.9 with the hash engine (depending on its hash). We
can even design tests around known seeds: e.g. if "bad" always maps to
negative above threshold, we know it should be transformed. 2. **Apply
transformation logic:** We feed the classification result into our
transformation algorithm (or call the pipeline end-to-end with the mode
set to use text_hash engine internally). We then inspect the output
HTML. 3. **Verify deterministically:** Because everything is
deterministic, we can assert that the output matches exactly the
expected transformed HTML string.

For instance, using the earlier Example 1 scenario, we can write a test
expecting that with `mitm-mode=xxx-negative` and using text_hash engine,
the phrase "absolutely terrible!" in the input will always be identified
as negative and replaced with the exact pattern of x's. We can verify
that output contains "xxxxxxxxxx xxxxxxxxx!" at the correct place. If
the output differs, then something is off in our logic.

We should test each new mode: - Masking: ensure letters and digits
become \'x\', punctuation intact. - Grouping: ensure output letters
\'a\'..\'e\' are applied correctly based on length (we might craft test
words of specific lengths 2,5,7, etc., and verify they map to
\'aa\',\'bbbbb\',\'ccccccc\' as per the design). - Emoji: since
text_hash produces pseudo-sentiments, we can pick an input that we know
hash-engine will classify as negative (or we force classification by
constructing the filter differently) and confirm the text is replaced by
the correct emoji character. We must be careful to verify Unicode
handling (the emoji character should appear correctly in the UTF-8
output). - Blank removal: verify the text content is gone. Possibly
check that the element still exists but empty, or replaced by a
placeholder if we do that. - Blurring: Here we verify that the HTML
output contains the CSS style attribute or class that triggers blur
(since we can't "see" blur in a test, we check the markup). E.g. ensure
`<span class="blur-text">` is present or style with `filter:blur` is
injected. - Images: We simulate an HTML with an image and some text. We
then check that if the text is flagged, the image tag in output contains
the expected modifications (like `filter: blur` or replaced src). Using
the hash engine, we might not directly classify images, but we can
dummy-flag them by virtue of associated text classification. So, for a
test, we know a certain text "violence" will be flagged; we place an
`<img>` next to it, and after transform, expect the `<img>` tag to have
changed.

Another beneficial aspect of determinism is we can generate *zero-cost
test data*. We could run a large set of sample texts through the hash
engine offline to see what sentiment it assigns, and plan our test
inputs such that each sentiment category is covered. For example, find a
word that hash-engine classifies as positive with score 0.9, another
that it classifies as negative 0.95, etc. (The Semantic service docs
might even list some deterministic mappings in an appendix; if not, we
can brute force small words because the hash is seeded -- but that\'s an
aside.)

Because the text_hash engine has no real "accuracy" (it's essentially
random but fixed per input), we treat it purely as a predictable
labeler. In tests, we don't mind *what* label it gives as long as it's
consistent. We will calibrate our filter thresholds in tests to make
sure some texts pass and some fail: - e.g. If the hash engine gives
"okay" a neutral 0.6, and "terrible" a negative 0.8, and threshold is
0.7 for negative, then "terrible" should transform, "okay" not. Our test
would confirm that outcome.

Additionally, we should test **round-trip determinism**: If we transform
the same HTML twice with the same mode, we should get the same result
each time (and ideally idempotent if applied on already transformed
output, though we typically won't re-transform an already transformed
page). But just to be safe: our transformations generally replace text
irreversibly. If we accidentally piped the output back into the proxy,
it might try to transform again (double applying). We could ensure that
adding a marker like a data-attribute to processed elements could
prevent double-processing in one pass. However, the architecture caches
results so re-fetching the same page with the same cookie should serve
from cache the identical output, guaranteeing consistency without
reprocessing.

We will write unit tests for the transformation functions (like a
function that masks text, a function that generates the ABCDE pattern,
etc.) with predetermined inputs and outputs. We'll also write
integration tests using mitmproxy in a test mode or directly calling the
HTML and Semantic services with test data.

**Performance and determinism in testing:** Using text_hash means no
external calls, which speeds up tests significantly. The HTML Service
calls (to break and rebuild HTML) are local or fast operations we can
allow in tests (or we can mock them with known outputs if we want pure
unit tests without actual HTML parsing). The cache can be disabled or
cleared in tests to always exercise the transformation logic.

Finally, we emphasize that **deterministic results give us confidence to
deploy**: we can test on a staging site with known content, and be sure
the transformations will behave exactly as tested when live (assuming
using the same engine or that AWS Comprehend will flag similar content
at least, albeit AWS might have slight variations -- but for functional
testing we stick to deterministic mode). This strategy (develop with
text_hash, then switch engine to AWS for real data) is explicitly
recommended and we will follow it.

## 7. Implementation Recommendations

With the new features defined, we need to integrate them into the system
architecture in an efficient and maintainable way. The main decision is
whether to **extend the existing HTML Service** to handle these
transformation rules (clustering, images, new modes), or to **introduce
a dedicated Transformation Service** that would sit between the Semantic
Text Service and the final HTML assembly. We will evaluate both
approaches:

**Option 1: Extend the HTML Service (or the proxy's HTML processing
logic)**

*Pros:*
- **Simpler pipeline:** We keep the 3-step pipeline as is (HTML Service
‚Üí Semantic Service ‚Üí HTML Service), and just enhance what happens in
those steps. The HTML Service already reconstructs HTML from text
hashes, so it's natural to embed additional logic there to handle
clusters and images before final output. We can modify the HTML
Service's second call (hashes‚ÜíHTML) to accept not just a direct hash
mapping, but perhaps also instructions for removals or DOM-level
transformations. Since we have the parsed DOM (html_dict) in the HTML
Service context, it can easily remove or wrap elements as needed before
serializing back to HTML. - **Lower latency:** Avoids introducing
another network call. Each additional microservice would add overhead
(HTTP call + serialization). Currently after Semantic Text Service
returns, the proxy directly uses HTML Service to rebuild HTML. If we
added a Transformation Service, we'd likely send data to it and then
either reconstruct HTML there or send back instructions. Extending HTML
Service does everything in one go. - **Unified responsibility for HTML
structure:** The HTML Service is already responsible for parsing and
constructing HTML. It likely has functions to manipulate the DOM tree
(it outputs html_dict). It can be extended to also *modify* that DOM
tree according to transformation rules. This keeps all HTML-specific
logic in one place. The Semantic Text Service remains focused on
classification and simple text transforms (like mask, hash, etc.)
without worrying about multi-node context. - **Less complexity in
deployment:** One less service to deploy and maintain. We just
version-up the HTML Service with new capabilities. Also less
inter-service communication complexity (no need for another client
library or error handling for an extra service). - **Cache integration
remains straightforward:** The cache is currently keyed by URL and
transformation mode (likely including engine and criteria). If we keep a
single service doing the final assembly, caching the final HTML per mode
is easy. If another service was involved, we might need to cache
intermediate results too or consider its caching.

*Cons:*

- **HTML Service bloat:** The HTML Service would now take on more logic:
deciding cluster grouping, applying filters to images, etc. This goes
beyond simple parsing/serializing; it starts encroaching on what could
be considered "business logic" of the transformation. Maintaining and
testing these rules could make the HTML Service code more complex. -
**Limited perspective in HTML Service:** The HTML Service as currently
used may not know anything about sentiment scores, only the transformed
text that Semantic returns. If we want to make decisions like "remove
this whole `<div>` because it contained 3 negative spans", the HTML
Service would need more than just the final transformed strings -- it
needs to know which nodes were flagged. We might have to change the
interface between Semantic Service and HTML Service. For example,
Semantic Service could return not only `transformed_mapping`, but also a
list of hashes that were transformed (or a parallel mapping of
hash‚Üíscore or flag). The technical guide hints that Semantic can return
full ratings or at least we could request them. Alternatively, we could
encode a special marker into transformed text for cluster handling (like
Semantic returns "\[NEGATIVE\]" or some token for certain hashes, which
the HTML Service then interprets to mean "this was negative"). That's a
bit hacky. A cleaner way: have the proxy gather the sentiment info from
Semantic (maybe using a different output mode or an extended schema) and
then pass that to HTML Service. This is doable: e.g., instead of calling
`POST /hashes/to/html` with just hash‚Üítransformed_text, we could call a
new endpoint `POST /transform/html` with hash‚Üítransformed_text plus a
list of hash‚Üíflags or meta. We'd then update HTML Service to accept that
and handle accordingly. - **Coupling**: By extending HTML Service to
know about sentiment flags, we couple it with the Semantic Service's
domain. A dedicated transformation layer could act as the broker that
understands both the DOM and the meaning of scores, whereas HTML Service
originally was sentiment-agnostic. However, since this project is
specifically about sentiment-based transforms, that coupling is probably
acceptable.

**Option 2: New Transformation Service**

In this scenario, after we get the classification results from Semantic
Text Service, we pass the data to a **Transformation Service**
responsible for applying cluster logic, deciding on text vs. image
operations, and producing the final HTML (or modified html_dict). The
pipeline might become: HTML Service (to hashes) ‚Üí Semantic Service
(classification) ‚Üí Transformation Service (apply rules) ‚Üí (maybe back to
HTML Service to rebuild HTML if Transformation service outputs a
structure) ‚Üí out to client. We could also integrate the final HTML
assembly into the Transformation Service itself (i.e., Transformation
Service could take the original HTML and do the entire job of producing
transformed HTML by internally using the HTML parsing library --
essentially doing the HTML Service's job).

*Pros:*

- **Separation of concerns:** The Transformation Service would
encapsulate all the high-level logic about sentiment filtering,
clustering, UI transformations. It would receive structured input and
output structured (or final HTML) output. This keeps the HTML Service
"dumb", just doing parsing and reassembly as it does now. Semantic
Service stays "dumb" in that it just scores and transforms text
fragments individually. The new service sits in between to make the
holistic decisions. - **Easier to maintain complex logic:** Having a
dedicated service means we can iterate on transformation rules
independently, possibly deploy it separately. If the logic grows (which
it might, as we add more modes or special cases), it's contained in one
codebase. - **Flexibility in output:** The Transformation Service could
directly output the final HTML string to the proxy. This means we
wouldn't need a second call to HTML Service at all if we feed it enough
info. For example, it could take the original HTML and the
classification results and do find-and-replace or DOM manipulation
itself. We could use an HTML parser library in this service similar to
what HTML Service does. In fact, we might reuse or incorporate the HTML
Service's parsing logic here. The benefit is we can do non-standard
things like removing entire elements or adding attributes (which the
current `hashes‚ÜíHTML` call may not support easily since it just replaces
text nodes). - **Potential for reusability:** If we build Transformation
Service right, it could be reused for other projects that need to
manipulate HTML based on classifications (not just sentiment). It would
basically be an engine where you feed in an HTML plus annotations and
rules, and get an output. This might be outside our immediate scope, but
it's a thought.

*Cons:*

- **Increased complexity in integration:** Introducing a new service
means more moving parts. The proxy now has to coordinate three services
instead of two. We'd have to implement a robust client for the
Transformation Service, with retries, error handling, etc., similar to
how HTML and Semantic services are handled. - **Latency overhead:**
Another HTTP round-trip for each page. If each service call is, say,
100ms, adding one more could be noticeable. If the Transformation
Service does heavy DOM operations in Python, that also adds processing
time (though likely small relative to network). - **Data transfer
overhead:** What do we send to the Transformation Service? Possibly the
entire HTML (which could be large) plus maybe the classification scores
for each text segment. That's a lot of data to serialize to JSON. The
current approach avoids sending full HTML to Semantic Service (it sends
only text content mapping to Semantic, not the whole HTML). If
Transformation Service needs the HTML structure and classification, we
might send the `html_dict` (which is a structured representation) along
with maybe a dictionary of hash-\>scores/flags. This is doable but
heavy. Alternatively, we send the original HTML string and a list of
flagged text strings or positions, and let the Transformation Service
parse it again -- duplicating what HTML Service already did. -
**Consistency:** Keeping HTML parsing logic in sync between HTML Service
and Transformation Service could be an issue. If both need to parse or
interpret the DOM, we might duplicate code or have slight differences.
We might mitigate that by versioning or having Transformation Service
call HTML Service internally (but that again, layering calls might
defeat the purpose).

**Recommended Approach:**

Given the above, a pragmatic path is to **incrementally extend the
existing HTML Service** for this next phase. We can augment the
interface between Semantic Text Service and HTML Service to carry the
needed information for clustering and images. For example, after
classification, our proxy can compile a list of which hashes were
transformed/flagged (the Semantic response likely can tell us how many
were transformed and we can infer which those were by comparing input
and output or using a planned extension). We could then call
`POST /hashes/to/html` as usual to get the basic HTML, and then do a
post-processing pass within the proxy script itself to handle clusters
and images. In fact, there's a third hybrid approach: do minimal extra
work in HTML Service and finalize some transforms in the proxy's Python
addon.

**Hybrid approach (for Phase 2):**

- Let Semantic Text Service handle individual text transformations
(masking, hashing, etc.) because it's already set up to do that per
hash. - Extend Semantic's output or use a parallel output to identify
sentiment flags. If Semantic Text Service had a mode
`hashes-with-scores`, we could use that to get each hash's sentiment
scores without transforming text (or it could transform with
placeholders). - Use HTML Service to reconstruct HTML with whatever
transformed text comes (for e.g., emoji mode, it would place emojis in
text positions which is fine). - Then, in the **mitmproxy addon
(Python)**, do an extra sweep over the HTML string or the DOM (the addon
could parse the HTML if needed, or perhaps we can instruct HTML Service
to do some marking). The mitmproxy script could remove whole elements or
add blur by injecting CSS styles at this point, since it has the final
HTML as a string. Python's lxml or a simple regex could handle adding
`filter:blur` to image tags that need it, for instance.

However, modifying HTML via regex can be error-prone; using a DOM parser
in the proxy addon is possible but duplicative. A cleaner way:
incorporate those modifications in the HTML Service itself before it
returns the HTML. We might call HTML Service with an augmented
`hash_mapping` where some hash values map to special tokens indicating a
removal. For instance, if we decide an entire `<p>` should be removed,
we could supply its text hash mapping as `""` (empty) and perhaps also
include a hint to remove parent. The HTML Service currently might not
remove parent elements just because text is empty, it would just place
an empty string. But we could modify HTML Service code: e.g., if a hash
mapping value is a special string like `__DELETE_PARENT__`, the service
could strip the parent node from output. That requires encoding parent
relationships in the hash map, which it currently doesn't have.

Perhaps a better solution: extend HTML Service's `html_dict` to mark
nodes with flags for removal or blurring, and have a transformation step
that applies those before serialization. We could for example add an
entry in `hash_mapping` for an image's *alt text or src* to indicate it
should be blurred. This is hacky; instead, maybe let HTML Service return
a JSON structure and have the proxy finalize the transformation.

Given time constraints, I recommend: - Implement clustering logic in the
**proxy layer** using the data we have: e.g., gather all text nodes
classified as negative, identify their DOM parents via the `html_dict`
(if html_dict gives node indices or hierarchy, the proxy could analyze
that). The `html_dict` from the first HTML Service call does include a
tree structure. We have that before sending to Semantic. We could store
it, and after getting results, walk it to decide cluster actions. Then
instruct HTML Service second call accordingly (maybe by removing certain
hashes or replacing text). - Implement image blurring in the **proxy
layer** as well: after getting final HTML, insert a `<style>` tag or
modify `<img>` tags with a simple search-and-replace if the images have
an `id` or something. Or better: during cluster analysis, if we know an
image's parent is flagged, we can directly inject a small CSS snippet
before returning the response. For instance, add
`img[data-flagged] { filter: blur(5px); }` and also add
`data-flagged="1"` to those image tags via string replacement. Since the
number of images to blur is small, and the HTML should have the exact
`<img src="...">` string, a regex or string find could locate it. We
must be careful not to accidentally replace something unintended.

In the long run, a refactored HTML Service that can accept
transformation directives would be ideal, but for this phase, leveraging
the proxy's ability to manipulate the response might speed up
development. The mitmproxy addon runs in Python and can alter the HTML
text directly as it intercepts it.

**Interface Contract (Design) for Transformations:**

Whether extended in HTML Service or handled partly in proxy, we define
an internal interface/contract for how transformations are applied: -
**Input to transformation stage:** - DOM structure (`html_dict` from
HTML Service Step 1) with unique identifiers for text nodes (hashes). -
Classification results for each text hash (either in form of transformed
text from Semantic or separate scores). - Configuration (selected mode,
threshold, cluster setting, etc.). - **Process:** 1. Merge
classification info into the DOM representation: e.g., annotate each
text node in `html_dict` with a flag like `flag="negative"` if it meets
criteria. 2. Determine cluster groups: e.g., traverse `html_dict` and if
a parent element has multiple flagged children, mark the parent as
`cluster_flag="negative"`. Possibly propagate upward for nested
structure. We decide whether to cluster at first negative ancestor or
fixed level like `<p>` or `<div class="section">` depending on config.
3. Apply transformations: - For each text node: - If it's flagged and
**no cluster parent is taking over**, transform its content according to
the mode (if Semantic already gave transformed text, we might just use
that, except in modes where Semantic didn't handle it like blur). - If
not flagged, leave it. - For each image node: - If it's inside a flagged
cluster (or adjacent to a flagged text), mark it for image transform
(blur or hide). - For each parent cluster flagged: - Depending on
transformation mode and severity, either remove the element or replace
its inner content with a placeholder. Removal could mean actually not
outputting that element and all inside it. - Ensure that if parent is
removed, child text transformations are not separately output (since
they're gone). - If mode is something like blur cluster, we might add a
CSS class to that element (e.g. `class="blur-content"`) that in a
stylesheet blurs all text inside or overlays a blur. Or apply inline
`style="filter: blur(...)"` to the container which would blur its entire
rendering (including text and images -- which is another neat trick:
applying `filter: blur` on a container blurs all its children content as
one graphic, which might simplify cluster blur). - Compose the final
HTML output (either via HTML Service or by constructing manually). -
**Output from transformation stage:** - The modified HTML content ready
to send to the user, or a modified DOM structure that the HTML Service
can serialize. If using HTML Service to do final assembly, our interface
could be: `POST /hashes/to/html` with an **augmented hash_mapping**: -
normal text hashes map to either transformed text (from Semantic) or if
removed to `""`. - possibly a special entry for cluster placeholders
(though HTML Service might not know how to insert a whole new node). We
might instead decide to do final assembly ourselves if cluster removal
is needed.

For clarity, we might decide on a **contract for removal or cluster
transforms** such as: - If an entire element is to be removed, perhaps
set all its child text hashes' transformed value to an empty string and
also include a special comment in the output indicating removal. But
empty strings alone won't remove the element tag, it will just make it
empty. - Alternatively, add a special dummy hash in the structure
representing the whole element's content. The HTML Service doesn't
currently hash container nodes, just text, so not straightforward. -
Another idea: perform two passes of HTML assembly -- one normally, then
parse that output in the proxy and remove the undesired parts with a
simpler method.

Given the complexity, an iterative approach: start without automated
removal of whole tags. We can initially implement cluster by simply
blanking the text inside those tags (so the element remains but with no
text, and maybe we can hide images by replacing their `src` with a 1x1
pixel or something). This achieves the effect of not showing content,
albeit leaving empty containers. Later, we can refine to remove the
container if needed for cleanliness.

**Conclusion:**

We will proceed by extending our current services as needed, leaning on
the HTML Service for structured HTML handling and using the proxy layer
for any tweaks that are simpler there.

The interface between components will be updated as follows: - **Proxy
to Semantic Service:** Already defined by `transform` endpoint; we'll
add new `transformation_mode` values for "EMOJI", "BLANK" (for removal),
etc. If Semantic Service doesn't implement those, it may ignore them or
we use TEXT_HASH engine to just classify and not transform text for
those modes. Possibly we need to enhance Semantic Service to support an
"emoji" mode where it returns an emoji character for each filtered text
(the Semantic Text Service could technically do that since it knows the
sentiment label). - **Semantic to Proxy/HTML Service:** We may enhance
the response to include metadata. If not, the proxy can infer which
texts were changed by comparing transformed_mapping vs original (if a
text remained identical, it was not filtered; if changed, it was). -
**Proxy/HTML to HTML Service (2nd call):** We might need to give HTML
Service not just the hash-\>text map, but also e.g. a list of elements
to drop or attributes to add. One quick method: We could insert **HTML
comments** as placeholders via the transformed text to signal something.
For example, if we want to drop an image, we could set its preceding
text's transformed value to `<!--IMG_OFF-->` or something, and then have
the proxy remove the actual `<img>` tag by searching for that comment in
the output. This is hacky but can work without altering HTML Service
API. A cleaner solution is to implement directly in HTML Service code:
but that would require adding new fields to its input JSON (which we can
do since we control it). For instance, extend `hash_mapping` to include
entries for image URLs or some special keys for nodes to blur/hide.

Given our time frame for Phase¬†2, I'd lean on **minimally invasive
tactics**: - Use the cookie to control everything from the proxy. - Use
existing service calls as much as possible. - Do final adjustments in
the proxy on the HTML string if needed, as a stopgap.

After prototyping and proving these transformations work, we can
refactor in Phase¬†3 perhaps, to either spin off a service or formally
enhance HTML Service's API.

**Summary of Implementation Steps:**

1. **Extend Semantic Text Service**: Add new `transformation_mode`
options for \"EMOJI\". This could map sentiment categories to emoji
internally (Semantic can decide which emoji to return for a given hash's
sentiment -- or it could return a placeholder like \"\[NEG\]\" and we
replace it in HTML Service; but better to return actual emoji). For
"BLANK" mode, Semantic could just return empty string for filtered text.
For "NOTICE" mode, maybe return a fixed string like \"\[hidden\]\".
These would make it easy as the HTML Service would just insert those
strings in place. If Semantic Service can't be changed in time, we use
existing ones: e.g. use XXX mode but then do a replace of \'x\' with \'
\' to blank out in proxy -- not ideal. 2. **Proxy logic**: Parse cookie
to get mode, category, threshold. Configure the Semantic request
accordingly. After receiving response: - If clustering is enabled, parse
the original html_dict (from Step 1) to identify clusters. Possibly
re-parse the output HTML or track positions. Then modify the HTML
accordingly (remove or additional masks). This is tricky; might focus on
simpler cluster effect first (like just mask entire paragraph by
replacing all its text with X if multiple negatives found -- which
Semantic might have already done if we gave it all text? If one text
node was entire paragraph, then no problem). - For images: find any
`<img>` tags in the output string that are within `negative-cluster` (we
could add a span or comment around clusters to mark them before
assembly). - Insert CSS for blurring if needed, or directly add style
attributes via search/replace.

1.  **HTML Service**: Potentially update to handle any special markers
    from Semantic. For example, if Semantic returns an emoji or a
    special token, ensure it doesn't get escaped or lost. The HTML
    Service likely treats transformed text as safe content to insert
    (since originally it's supposed to be the same text or masked text).
    We should ensure that inserting emoji (UTF-8) works -- test it. Also
    ensure that if an empty string is inserted for some hash, the HTML
    Service doesn't drop the tag. It should just produce an empty text
    node which is fine.

2.  **Testing**: Use text_hash engine to simulate and verify as
    discussed. Particularly test that cluster logic doesn't break when
    content is partially filtered vs fully filtered.

**Future Refactor**: If the transformation logic proves too heavy for
the proxy or HTML Service, we can spin it out. The interface for a new
Transformation Service could be:

    POST /transform 
    {
      "html": "<original HTML or partial HTML>",
      "classifications": [ 
          { "text_hash": "abc123", "sentiment": "negative", "score": 0.85 },
          ... 
       ],
      "transform_mode": "blur",
      "cluster_mode": "paragraph",
      "image_mode": "blur"
    }
    => returns "<transformed HTML>"

Something like that. It would internally parse the HTML, apply
operations, and output final HTML. This would be a clean API boundary.
But implementing a full HTML parser in that service duplicates what HTML
Service does. Alternatively, we feed it `html_dict` instead of raw HTML:

    {
      "html_tree": {...}, 
      "transformed_mapping": {...}, 
      "flags": { "hash1": "negative", ... },
      "cluster": "block",
      "images": "remove"
    }
    => returns modified html_tree or final HTML

We could even have it return diffs or instructions. However, this is a
major design which might be beyond Phase¬†2 scope.

Thus, **for Phase 2** we stick to bolting on to what we have: - Leverage
`text_hash` for testing deterministically. - Use cookies to toggle each
new feature easily during development and demos. - Make sure each
transformation mode is as deterministic as the others -- e.g., emoji
mapping should not randomly pick emojis; it should be a fixed mapping
table (so that given the same sentiment, it always uses the same emoji,
ensuring repeatability). - Monitor performance with added logic; if page
load is too slow with Python post-processing for big pages, we might
push more into the services.

Finally, update documentation and the admin UI to reflect these new
modes and how to use them. Technical architects and developers will then
have a clear blueprint of how Phase¬†2 transformation works within the
mitmproxy pipeline, and how to configure and extend it going forward.
