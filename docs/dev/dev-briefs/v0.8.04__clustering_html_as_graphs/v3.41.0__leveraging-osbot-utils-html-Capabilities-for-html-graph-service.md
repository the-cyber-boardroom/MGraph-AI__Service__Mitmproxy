# Leveraging OSBot-Utils HTML Capabilities for HTML Graph Service

**version** v3.41.0 (OSBot-Utils)

Based on the documentation, here's how the `/html/` capabilities can be strategically leveraged for creating HTML graphs:

## üéØ Core Mapping Strategy

### 1. **HTML Structure ‚Üí Graph Structure**

The HTML parser's type-safe schema can be directly mapped to graph nodes and edges:

```python
# HTML Element ‚Üí Graph Node
Schema__Html_Node {
    tag: 'div'           ‚Üí Node.type = 'HTMLElement'
    attrs: {...}         ‚Üí Node.properties = {...}
    position: 0          ‚Üí Node.order = 0
}

# Parent-Child Relationship ‚Üí Graph Edge
child_nodes: [...]     ‚Üí CONTAINS edges
text_nodes: [...]      ‚Üí HAS_TEXT edges
```

### 2. **Position Tracking = Order Preservation**

The position-based system is **critical** for HTML graphs:
- Maintains DOM order in graph queries
- Enables "next sibling" / "previous sibling" edges
- Preserves reading order for content extraction

```python
# From the parser
text_nodes: [
    Schema__Html_Node__Data(data='Before', position=0),
    Schema__Html_Node__Data(data='After', position=2)
]
child_nodes: [
    Schema__Html_Node(tag='p', position=1)
]

# Becomes graph edges with order
(Container)-[CONTAINS {order: 0}]->(Text:Before)
(Container)-[CONTAINS {order: 1}]->(Element:p)
(Container)-[CONTAINS {order: 2}]->(Text:After)
```

## üîß Key Capabilities to Leverage

### A. **Html__Query for Pattern Extraction**

Use the existing query system to identify graph-worthy patterns:

```python
with Html__Query(html=html_content) as query:
    # Extract navigation structures
    nav_links = query.find_by_tag('nav')
    
    # Extract semantic relationships
    for link in query.find_all_by_tag('a'):
        href = query.get_attribute(link, 'href')
        # Create LINKS_TO edges in graph
    
    # Extract content hierarchy
    headings = query.find_by_tag('h1') + query.find_by_tag('h2')
    # Create SECTION_OF edges in graph
```

### B. **Type-Safe Schema for Graph Nodes**

The `Schema__Html_Document` structure maps cleanly to graph properties:

```python
# Each Schema__Html_Node becomes a graph node with:
{
    'node_type': 'HTMLElement',
    'tag': node.tag,
    'element_id': node.attrs.get('id'),
    'classes': node.attrs.get('class', '').split(),
    'position': node.position,
    'attributes': node.attrs,
    'text_content': collect_text(node)
}
```

### C. **Roundtrip Capability = Graph Reconstruction**

The perfect roundtrip conversion enables:

1. **Import**: HTML ‚Üí Schema ‚Üí Graph
2. **Query/Transform**: Graph operations
3. **Export**: Graph ‚Üí Schema ‚Üí HTML

This means you can:
- Store HTML in graph form
- Perform graph queries/transformations
- Regenerate valid HTML

## üìä Specific Graph Patterns to Extract

### 1. **Document Structure Graph**

```python
# Using Html__Query properties
with Html__Query(html=html) as query:
    # Document metadata
    title = query.title
    meta_tags = query.meta_tags
    
    # Create document node
    doc_node = {
        'type': 'HTMLDocument',
        'title': title,
        'meta': meta_tags,
        'timestamp': query.document.timestamp
    }
```

### 2. **Link Graph**

```python
# Extract all hyperlink relationships
with Html__Query(html=html) as query:
    for link_elem in query.find_by_tag('a'):
        source_id = get_parent_id(link_elem)
        target_href = query.get_attribute(link_elem, 'href')
        link_text = query.get_text(link_elem)
        
        # Create LINKS_TO edge with properties
        edge = {
            'type': 'LINKS_TO',
            'href': target_href,
            'text': link_text,
            'rel': query.get_attribute(link_elem, 'rel')
        }
```

### 3. **Resource Dependency Graph**

```python
with Html__Query(html=html) as query:
    # CSS dependencies
    for css_href in query.css_links:
        # Create USES_STYLESHEET edge
        
    # Script dependencies  
    for script_src in query.script_sources:
        # Create LOADS_SCRIPT edge
        
    # Favicon
    if query.favicon:
        # Create HAS_FAVICON edge
```

### 4. **Content Hierarchy Graph**

```python
# Extract semantic structure
def extract_content_sections(query):
    sections = []
    current_section = None
    
    for elem in query.find_all():
        if elem.tag in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:
            # Start new section
            level = int(elem.tag[1])
            current_section = {
                'type': 'Section',
                'level': level,
                'heading': query.get_text(elem),
                'content': []
            }
            sections.append(current_section)
        elif current_section and elem.tag == 'p':
            # Add content to current section
            current_section['content'].append(query.get_text(elem))
    
    return sections
```

## üèóÔ∏è Recommended Architecture

### Layer 1: HTML Parsing (OSBot-Utils)
```python
# Use existing pipeline
html ‚Üí Html__To__Html_Document() ‚Üí Schema__Html_Document
```

### Layer 2: Graph Extraction (New Service)
```python
# Transform schema to graph nodes/edges
Schema__Html_Document ‚Üí extract_graph_structure() ‚Üí MGraph nodes/edges
```

### Layer 3: Graph Storage (MGraph-DB)
```python
# Store in graph database
MGraph nodes/edges ‚Üí MGraph_DB.add() ‚Üí Persistent graph
```

### Layer 4: Graph Queries (New Service)
```python
# Query patterns
MGraph_DB.query() ‚Üí Graph traversals ‚Üí Results
```

## üí° Key Advantages

1. **Proven Parser**: The HTML parser has comprehensive test coverage
2. **Type Safety**: Schema objects provide validation
3. **Position Tracking**: Critical for DOM order preservation
4. **Mixed Content**: Handles text + elements correctly
5. **Roundtrip**: Can reconstruct original HTML from graph
6. **Query Interface**: `Html__Query` provides pattern extraction

## üöÄ Implementation Strategy

### Phase 1: Direct Mapping
```python
def html_to_basic_graph(html: str) -> MGraph:
    # Parse HTML
    document = Html__To__Html_Document(html=html).convert()
    
    # Create graph
    graph = MGraph()
    
    # Map each node
    def add_node_to_graph(html_node, parent_id=None):
        node_id = graph.add_node(
            type='HTMLElement',
            tag=html_node.tag,
            attrs=html_node.attrs,
            position=html_node.position
        )
        
        if parent_id:
            graph.add_edge(parent_id, node_id, 'CONTAINS', 
                          order=html_node.position)
        
        # Recurse for children
        for child in html_node.child_nodes:
            add_node_to_graph(child, node_id)
        
        # Add text nodes
        for text in html_node.text_nodes:
            text_id = graph.add_node(
                type='TextNode',
                content=text.data,
                position=text.position
            )
            graph.add_edge(node_id, text_id, 'HAS_TEXT',
                          order=text.position)
        
        return node_id
    
    add_node_to_graph(document.root_node)
    return graph
```

### Phase 2: Semantic Extraction
```python
def extract_semantic_graph(html: str) -> MGraph:
    base_graph = html_to_basic_graph(html)
    
    with Html__Query(html=html) as query:
        # Add link edges
        for link in query.find_by_tag('a'):
            source_id = find_node_id(link)
            target_href = query.get_attribute(link, 'href')
            base_graph.add_edge(source_id, target_href, 
                               'LINKS_TO', type='external')
        
        # Add section hierarchy
        sections = extract_sections(query)
        for section in sections:
            add_section_to_graph(base_graph, section)
    
    return base_graph
```

### Phase 3: Advanced Patterns
```python
def extract_patterns(html: str) -> Dict[str, MGraph]:
    """Extract multiple graph views from HTML"""
    return {
        'structure': extract_dom_graph(html),
        'links': extract_link_graph(html),
        'content': extract_content_graph(html),
        'resources': extract_resource_graph(html),
        'forms': extract_form_graph(html)
    }
```

## üìù Recommendations

1. **Start with `Html__To__Html_Document`**: This gives you the cleanest structure to work with
2. **Use `Html__Query` for pattern extraction**: Leverage its high-level methods for semantic analysis
3. **Preserve position information**: Essential for maintaining DOM order in graph
4. **Map schemas directly to nodes**: The type-safe structure translates cleanly
5. **Consider multiple graph views**: Create different graphs for different use cases (structure, links, content, etc.)