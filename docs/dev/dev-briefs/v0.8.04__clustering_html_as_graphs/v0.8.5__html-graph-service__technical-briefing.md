# Html-Graph Service: Technical Implementation Briefing

**Version:** v0.8.5  
**Service URL:** https://html-graph.dev.mgraph.ai  
**Target Audience:** LLM implementing this service  
**Last Updated:** November 20, 2025

---

## Table of Contents

1. [Executive Summary](#1-executive-summary)
2. [Service Purpose & Architecture](#2-service-purpose--architecture)
3. [Type_Safe Schemas](#3-type_safe-schemas)
4. [API Endpoints](#4-api-endpoints)
5. [Core Implementation Classes](#5-core-implementation-classes)
6. [Integration with Mitmproxy Pipeline](#6-integration-with-mitmproxy-pipeline)
7. [MGraphDB Integration](#7-mgraphdb-integration)
8. [Performance & Caching](#8-performance--caching)
9. [Testing Strategy](#9-testing-strategy)
10. [Deployment Configuration](#10-deployment-configuration)

---

## 1. Executive Summary

### 1.1 Purpose

The Html-Graph Service is a FastAPI-based microservice that transforms HTML structures into multi-layer graph abstractions using mGraphDB. It enables intelligent content clustering for sentiment-based transformations by creating hierarchical representations (L0→L1→L2→L3) that maintain full bidirectional traceability to the original HTML structure.

### 1.2 Key Capabilities

**Core Features:**
- Multi-layer graph construction (L0, L1, L2, L3+)
- Automated content-only extraction (L1)
- Parent-based consolidation (L2)
- Pattern recognition and clustering
- Transform decision propagation
- Graph visualization (DOT, JSON)
- Comprehensive caching strategy

**Integration Points:**
- HTML Service: Receives html_dict input
- Semantic Text Service: Provides clustered text for classification
- Cache Service: Stores graph instances and analysis results
- Mitmproxy Service: Orchestrates transformation pipeline

### 1.3 Technology Stack

```python
Framework:     FastAPI 0.104+
Type System:   OSBot-Utils Type_Safe 3.28+
Graph Engine:  MGraph-DB 1.2.18+
Cache:         Redis (via Cache Service)
Validation:    Pydantic v2 compatible
Testing:       pytest with Type_Safe assertions
```

---

## 2. Service Purpose & Architecture

### 2.1 Problem Statement

Current HTML transformation operates at the text-node level, resulting in:
- **Fragmented classification**: Individual text fragments lack semantic context
- **Inconsistent transformations**: Adjacent text with similar sentiment treated differently  
- **Poor clustering**: No understanding of HTML structure (paragraphs, sections, cards)
- **High API costs**: Classifying many small text nodes instead of fewer meaningful units

### 2.2 Solution: Multi-Layer Graph Abstraction

The Html-Graph Service solves these problems by:

1. **Creating hierarchical views** of HTML structure at multiple abstraction levels
2. **Maintaining traceability** through unique ID references at each layer
3. **Enabling semantic clustering** based on structure rather than just content
4. **Optimizing classification** by operating at block/section level instead of text level
5. **Providing reversible transformations** that propagate correctly from high layers to L0

### 2.3 High-Level Architecture

```
┌─────────────────────────────────────────────────────────────────┐
│                    Html-Graph Service                           │
│              (html-graph.dev.mgraph.ai)                         │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  ┌────────────────────────────────────────────────────────┐   │
│  │  FastAPI Application Layer                             │   │
│  │  • Request validation (Type_Safe schemas)              │   │
│  │  • Endpoint routing                                    │   │
│  │  • Response formatting                                 │   │
│  └────────────────────────────────────────────────────────┘   │
│                          │                                     │
│  ┌────────────────────────────────────────────────────────┐   │
│  │  Graph Construction Engine                             │   │
│  │  • Html_Graph__Builder (L0→L1→L2→L3)                   │   │
│  │  • Html_Graph__Compressor (optimization)               │   │
│  │  • Html_Graph__Navigator (traversal)                   │   │
│  └────────────────────────────────────────────────────────┘   │
│                          │                                     │
│  ┌────────────────────────────────────────────────────────┐   │
│  │  Analysis & Clustering Engine                          │   │
│  │  • Pattern__Recognizer (detect HTML patterns)          │   │
│  │  • Cluster__Analyzer (optimal clustering)              │   │
│  │  • Transform__Propagator (L3→L2→L1→L0)                │   │
│  └────────────────────────────────────────────────────────┘   │
│                          │                                     │
│  ┌────────────────────────────────────────────────────────┐   │
│  │  MGraphDB Layer                                        │   │
│  │  • Schema definitions (nodes/edges)                    │   │
│  │  • Graph storage and queries                           │   │
│  │  • Index management                                    │   │
│  └────────────────────────────────────────────────────────┘   │
│                          │                                     │
│  ┌────────────────────────────────────────────────────────┐   │
│  │  Visualization Engine                                  │   │
│  │  • DOT graph generation                                │   │
│  │  • JSON export                                         │   │
│  │  • Layer-specific rendering                            │   │
│  └────────────────────────────────────────────────────────┘   │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
           │                  │                  │
           ▼                  ▼                  ▼
    ┌──────────┐      ┌──────────┐      ┌──────────┐
    │  Cache   │      │   HTML   │      │ Semantic │
    │ Service  │      │ Service  │      │   Text   │
    └──────────┘      └──────────┘      └──────────┘
```

---

## 3. Type_Safe Schemas

### 3.1 Core Schema Imports

```python
# Type_Safe Foundation
from osbot_utils.type_safe.Type_Safe                                                     import Type_Safe

# Core Safe Types
from osbot_utils.type_safe.primitives.core.Safe_Str                                     import Safe_Str
from osbot_utils.type_safe.primitives.core.Safe_Int                                     import Safe_Int
from osbot_utils.type_safe.primitives.core.Safe_UInt                                    import Safe_UInt

# Identifiers
from osbot_utils.type_safe.primitives.domains.identifiers.Safe_Id                       import Safe_Id
from osbot_utils.type_safe.primitives.domains.identifiers.Obj_Id                        import Obj_Id
from osbot_utils.type_safe.primitives.domains.identifiers.Random_Guid                   import Random_Guid
from osbot_utils.type_safe.primitives.domains.identifiers.Timestamp_Now                 import Timestamp_Now

# Domain Types
from osbot_utils.type_safe.primitives.domains.common.safe_str.Safe_Str__Text            import Safe_Str__Text
from osbot_utils.type_safe.primitives.domains.common.safe_str.Safe_Str__Version         import Safe_Str__Version
from osbot_utils.type_safe.primitives.domains.cryptography.safe_str.Safe_Str__Hash      import Safe_Str__Hash
from osbot_utils.type_safe.primitives.domains.http.safe_str.Safe_Str__Html              import Safe_Str__Html
from osbot_utils.type_safe.primitives.domains.http.safe_str.Safe_Str__Http__Content_Type import Safe_Str__Http__Content_Type
from osbot_utils.type_safe.primitives.domains.web.safe_str.Safe_Str__Url                import Safe_Str__Url

# Collections
from typing                                                                              import List, Dict, Optional, Set, Tuple

# MGraphDB
from mgraph_db.mgraph.domain.Domain__MGraph__Graph                                       import Domain__MGraph__Graph
from mgraph_db.mgraph.schemas.Schema__MGraph__Graph                                      import Schema__MGraph__Graph
from mgraph_db.mgraph.schemas.Schema__MGraph__Node                                       import Schema__MGraph__Node
from mgraph_db.mgraph.schemas.Schema__MGraph__Edge                                       import Schema__MGraph__Edge
from mgraph_db.mgraph.schemas.Schema__MGraph__Node__Data                                 import Schema__MGraph__Node__Data
from mgraph_db.mgraph.schemas.Schema__MGraph__Edge__Data                                 import Schema__MGraph__Edge__Data
```

### 3.2 Graph Lifecycle Schemas

#### 3.2.1 Graph Creation Request

```python
class Schema__Html_Graph__Create_Request(Type_Safe):
    """Request schema for creating a new HTML graph"""
    
    html                  : Optional[Safe_Str__Html]     = None     # Raw HTML input
    html_dict             : Optional[Dict]               = None     # From HTML Service
    hash_mapping          : Optional[Dict[str, str]]     = None     # Text hash mapping
    build_layers          : List[Safe_Int]                          # Which layers to build [0,1,2,3]
    enable_compression    : bool                         = True     # Apply L1 compression
    enable_pattern_detection : bool                      = False    # Detect HTML patterns
    cache_ttl             : Optional[Safe_UInt]          = 3600     # Cache TTL in seconds
```

#### 3.2.2 Graph Creation Response

```python
class Schema__Html_Graph__Layer_Stats(Type_Safe):
    """Statistics for a single graph layer"""
    
    layer_number          : Safe_Int                                # 0, 1, 2, 3, etc.
    node_count            : Safe_UInt                               # Total nodes in layer
    edge_count            : Safe_UInt                               # Total edges in layer
    text_node_count       : Safe_UInt                               # Count of text nodes
    element_node_count    : Safe_UInt                               # Count of element nodes
    compression_ratio     : Optional[Safe_Float__Percentage_Exact]  # vs previous layer


class Schema__Html_Graph__Create_Response(Type_Safe):
    """Response schema for graph creation"""
    
    graph_id              : Obj_Id                                  # Unique graph identifier
    created_at            : Timestamp_Now                           # Creation timestamp
    layers_built          : List[Safe_Int]                          # Layers successfully built
    layer_stats           : Dict[Safe_Int, Schema__Html_Graph__Layer_Stats]  # Stats per layer
    total_nodes           : Safe_UInt                               # Total across all layers
    total_edges           : Safe_UInt                               # Total across all layers
    build_time_ms         : Safe_UInt                               # Build duration
    cached                : bool                                    # Whether result was cached
    cache_key             : Optional[Safe_Str__Hash]                # Cache key if cached
```

### 3.3 Analysis & Clustering Schemas

#### 3.3.1 Cluster Analysis Request

```python
class Schema__Html_Graph__Analyze_Request(Type_Safe):
    """Request schema for analyzing graph clusters"""
    
    graph_id              : Obj_Id                                  # Graph to analyze
    classification_mode   : Safe_Id                                 # e.g., "xxx-negative"
    content_type          : Safe_Id                                 # "article", "list", "mixed"
    preferred_layer       : Optional[Safe_Int]       = None         # Preferred classification layer
    min_text_length       : Safe_UInt                = 10           # Minimum text per cluster
    max_clusters          : Safe_UInt                = 100          # Maximum clusters to return
```

#### 3.3.2 Cluster Node Schema

```python
class Schema__Html_Graph__Cluster_Node(Type_Safe):
    """Represents a cluster unit for classification"""
    
    cluster_id            : Obj_Id                                  # Unique cluster identifier
    layer_number          : Safe_Int                                # Source layer (typically L2 or L3)
    graph_node_id         : Obj_Id                                  # Node ID in graph
    aggregated_text       : Safe_Str__Text                          # Combined text content
    text_hash             : Safe_Str__Hash                          # Hash of aggregated text
    hash_references       : List[Safe_Str__Hash]                    # Original text hashes from HTML Service
    l0_node_ids           : List[Obj_Id]                            # All L0 nodes in cluster
    pattern_type          : Optional[Safe_Id]        = None         # Detected pattern if any
    child_cluster_ids     : List[Obj_Id]                            # Child clusters (if hierarchical)
    metadata              : Dict[Safe_Id, str]                      # Additional metadata


class Schema__Html_Graph__Analyze_Response(Type_Safe):
    """Response schema for cluster analysis"""
    
    graph_id              : Obj_Id                                  # Source graph
    recommended_layer     : Safe_Int                                # Optimal classification layer
    clusters              : List[Schema__Html_Graph__Cluster_Node]  # Cluster nodes
    total_clusters        : Safe_UInt                               # Count of clusters
    total_text_length     : Safe_UInt                               # Total characters across clusters
    analysis_time_ms      : Safe_UInt                               # Analysis duration
```

### 3.4 Transform Application Schemas

#### 3.4.1 Transform Decision Schema

```python
class Schema__Html_Graph__Transform_Decision(Type_Safe):
    """Decision about how to transform a cluster"""
    
    cluster_id            : Obj_Id                                  # Target cluster
    action                : Safe_Id                                 # "keep", "transform", "remove"
    transformation_mode   : Optional[Safe_Id]        = None         # "xxx", "emoji", "blank"
    transformed_text      : Optional[Safe_Str__Text] = None         # Replacement text (if applicable)
    metadata              : Dict[Safe_Id, str]                      # Additional transform metadata


class Schema__Html_Graph__Transform_Request(Type_Safe):
    """Request schema for applying transformations"""
    
    graph_id              : Obj_Id                                  # Target graph
    cluster_decisions     : List[Schema__Html_Graph__Transform_Decision]  # Decisions per cluster
    propagation_mode      : Safe_Id                  = "standard"   # "standard", "aggressive", "conservative"


class Schema__Html_Graph__Transform_Response(Type_Safe):
    """Response schema for transformation application"""
    
    graph_id              : Obj_Id                                  # Source graph
    transformed_hash_mapping : Dict[Safe_Str__Hash, Safe_Str__Text]  # Updated hash→text mapping
    l0_node_transforms    : Dict[Obj_Id, Safe_Str__Text]            # L0 node→transformed text
    clusters_transformed  : Safe_UInt                               # Count of transformed clusters
    total_transforms      : Safe_UInt                               # Total L0 nodes transformed
    propagation_time_ms   : Safe_UInt                               # Propagation duration
```

### 3.5 Visualization Schemas

#### 3.5.1 Visualization Request

```python
class Schema__Html_Graph__Visualize_Request(Type_Safe):
    """Request schema for graph visualization"""
    
    graph_id              : Obj_Id                                  # Graph to visualize
    layer                 : Optional[Safe_Int]       = None         # Specific layer (None = all)
    format                : Safe_Id                  = "dot"        # "dot", "json", "svg"
    include_metadata      : bool                     = True         # Include node metadata
    show_text_preview     : bool                     = True         # Show text content preview
    max_text_length       : Safe_UInt                = 50           # Max chars per node label


class Schema__Html_Graph__Visualize_Response(Type_Safe):
    """Response schema for visualization"""
    
    graph_id              : Obj_Id                                  # Source graph
    format                : Safe_Id                                 # Output format
    content               : Safe_Str__Text                          # Visualization content
    content_type          : Safe_Str__Http__Content_Type            # MIME type
    generation_time_ms    : Safe_UInt                               # Generation duration
```

### 3.6 Pattern Recognition Schemas

#### 3.6.1 Pattern Schema

```python
class Schema__Html_Graph__Pattern(Type_Safe):
    """Represents a detected HTML pattern"""
    
    pattern_id            : Obj_Id                                  # Unique pattern identifier
    pattern_type          : Safe_Id                                 # "paragraph-block", "bullet-list", etc.
    confidence            : Safe_Float__Percentage_Exact            # Detection confidence
    node_ids              : List[Obj_Id]                            # Nodes matching this pattern
    layer_number          : Safe_Int                                # Layer where detected
    metadata              : Dict[Safe_Id, str]                      # Pattern-specific metadata


class Schema__Html_Graph__Pattern_Detection_Response(Type_Safe):
    """Response schema for pattern detection"""
    
    graph_id              : Obj_Id                                  # Source graph
    patterns              : List[Schema__Html_Graph__Pattern]       # Detected patterns
    total_patterns        : Safe_UInt                               # Count of patterns
    coverage_percentage   : Safe_Float__Percentage_Exact            # Nodes covered by patterns
    detection_time_ms     : Safe_UInt                               # Detection duration
```

### 3.7 Health & Status Schemas

```python
class Schema__Html_Graph__Health_Response(Type_Safe):
    """Health check response"""
    
    service_name          : Safe_Id                  = "html-graph-service"
    version               : Safe_Str__Version                       # Service version
    status                : Safe_Id                                 # "healthy", "degraded", "unhealthy"
    timestamp             : Timestamp_Now                           # Check timestamp
    mgraph_db_available   : bool                                    # MGraphDB accessible
    cache_available       : bool                                    # Cache Service accessible
    active_graphs         : Safe_UInt                               # Currently cached graphs
    uptime_seconds        : Safe_UInt                               # Service uptime


class Schema__Html_Graph__Stats_Response(Type_Safe):
    """Service statistics response"""
    
    total_graphs_created  : Safe_UInt                               # Lifetime graph count
    total_analyses        : Safe_UInt                               # Lifetime analysis count
    total_transformations : Safe_UInt                               # Lifetime transform count
    cache_hit_rate        : Safe_Float__Percentage_Exact            # Cache effectiveness
    avg_build_time_ms     : Safe_UInt                               # Average graph build time
    avg_analysis_time_ms  : Safe_UInt                               # Average analysis time
```

---

## 4. API Endpoints

### 4.1 Graph Lifecycle Endpoints

#### POST /graph/create

**Purpose:** Create a new multi-layer graph from HTML

**Request Body:**
```python
Schema__Html_Graph__Create_Request
```

**Response:**
```python
Schema__Html_Graph__Create_Response
```

**Example:**
```bash
curl -X POST https://html-graph.dev.mgraph.ai/graph/create \
  -H "Content-Type: application/json" \
  -d '{
    "html_dict": {...},
    "hash_mapping": {...},
    "build_layers": [0, 1, 2, 3],
    "enable_compression": true,
    "enable_pattern_detection": false
  }'
```

**Response Example:**
```json
{
  "graph_id": "a1b2c3d4",
  "created_at": 1700000000000,
  "layers_built": [0, 1, 2, 3],
  "layer_stats": {
    "0": {"layer_number": 0, "node_count": 150, "edge_count": 149, ...},
    "1": {"layer_number": 1, "node_count": 87, "edge_count": 86, ...},
    "2": {"layer_number": 2, "node_count": 12, "edge_count": 11, ...},
    "3": {"layer_number": 3, "node_count": 3, "edge_count": 2, ...}
  },
  "total_nodes": 252,
  "total_edges": 248,
  "build_time_ms": 1247,
  "cached": false,
  "cache_key": "5eb63bbb01"
}
```

#### GET /graph/{graph_id}

**Purpose:** Retrieve graph metadata and statistics

**Response:**
```python
Schema__Html_Graph__Create_Response
```

#### DELETE /graph/{graph_id}

**Purpose:** Delete a graph from cache

**Response:**
```python
{"deleted": true, "graph_id": "a1b2c3d4"}
```

### 4.2 Analysis Endpoints

#### POST /graph/{graph_id}/analyze

**Purpose:** Analyze graph and generate optimal clusters for classification

**Request Body:**
```python
Schema__Html_Graph__Analyze_Request
```

**Response:**
```python
Schema__Html_Graph__Analyze_Response
```

**Example:**
```bash
curl -X POST https://html-graph.dev.mgraph.ai/graph/a1b2c3d4/analyze \
  -H "Content-Type: application/json" \
  -d '{
    "graph_id": "a1b2c3d4",
    "classification_mode": "xxx-negative",
    "content_type": "article",
    "min_text_length": 10,
    "max_clusters": 100
  }'
```

**Response Example:**
```json
{
  "graph_id": "a1b2c3d4",
  "recommended_layer": 2,
  "clusters": [
    {
      "cluster_id": "c1",
      "layer_number": 2,
      "graph_node_id": "L2_node_1",
      "aggregated_text": "This amazing product works well.",
      "text_hash": "abc123def4",
      "hash_references": ["hash_001", "hash_002", "hash_003"],
      "l0_node_ids": ["node_5", "node_7", "node_8"],
      "pattern_type": "paragraph-block",
      "child_cluster_ids": [],
      "metadata": {}
    }
  ],
  "total_clusters": 4,
  "total_text_length": 287,
  "analysis_time_ms": 156
}
```

#### GET /graph/{graph_id}/patterns

**Purpose:** Detect HTML content patterns in the graph

**Response:**
```python
Schema__Html_Graph__Pattern_Detection_Response
```

### 4.3 Transformation Endpoints

#### POST /graph/{graph_id}/apply-transforms

**Purpose:** Propagate cluster-level transformation decisions down to L0 nodes

**Request Body:**
```python
Schema__Html_Graph__Transform_Request
```

**Response:**
```python
Schema__Html_Graph__Transform_Response
```

**Example:**
```bash
curl -X POST https://html-graph.dev.mgraph.ai/graph/a1b2c3d4/apply-transforms \
  -H "Content-Type: application/json" \
  -d '{
    "graph_id": "a1b2c3d4",
    "cluster_decisions": [
      {
        "cluster_id": "c1",
        "action": "keep",
        "transformation_mode": null,
        "transformed_text": null,
        "metadata": {}
      },
      {
        "cluster_id": "c2",
        "action": "transform",
        "transformation_mode": "xxx",
        "transformed_text": "xxxxxxx xxx xxxxxxxx xxxxxxx",
        "metadata": {"sentiment": "negative"}
      }
    ],
    "propagation_mode": "standard"
  }'
```

**Response Example:**
```json
{
  "graph_id": "a1b2c3d4",
  "transformed_hash_mapping": {
    "hash_001": "This amazing product",
    "hash_002": "xxxxxxx xxx xxxxxxxx xxxxxxx",
    "hash_003": "Overall, I would recommend"
  },
  "l0_node_transforms": {
    "node_10": "xxxxxxx, xxx ",
    "node_12": "xxxxxxxx xxxxxxx",
    "node_13": " xxx xxxxxxxx xxx xxxxxxxxxxxx."
  },
  "clusters_transformed": 1,
  "total_transforms": 3,
  "propagation_time_ms": 89
}
```

### 4.4 Visualization Endpoints

#### GET /graph/{graph_id}/visualize

**Purpose:** Generate visual representation of graph structure

**Query Parameters:**
- `layer` (optional): Specific layer to visualize (0, 1, 2, 3)
- `format`: Output format ("dot", "json", "svg")
- `include_metadata`: Include node metadata (default: true)
- `show_text_preview`: Show text content in nodes (default: true)
- `max_text_length`: Max characters per node label (default: 50)

**Response:**
```python
Schema__Html_Graph__Visualize_Response
```

**Example:**
```bash
curl "https://html-graph.dev.mgraph.ai/graph/a1b2c3d4/visualize?layer=2&format=dot"
```

### 4.5 Health & Monitoring Endpoints

#### GET /health

**Purpose:** Service health check

**Response:**
```python
Schema__Html_Graph__Health_Response
```

#### GET /stats

**Purpose:** Service statistics and metrics

**Response:**
```python
Schema__Html_Graph__Stats_Response
```

---

## 5. Core Implementation Classes

### 5.1 Service Entry Point

```python
# File: src/html_graph_service/api/main.py

from fastapi                                                                             import FastAPI, HTTPException
from fastapi.middleware.cors                                                             import CORSMiddleware
from osbot_utils.type_safe.Type_Safe                                                     import Type_Safe

from html_graph_service.schemas.Schema__Html_Graph__Create_Request                      import Schema__Html_Graph__Create_Request
from html_graph_service.schemas.Schema__Html_Graph__Create_Response                     import Schema__Html_Graph__Create_Response
from html_graph_service.core.Html_Graph__Service                                        import Html_Graph__Service


class Html_Graph__Api(Type_Safe):
    """Main FastAPI application for Html-Graph Service"""
    
    app     : FastAPI
    service : Html_Graph__Service
    
    def __init__(self):
        self.app     = FastAPI(title    = "Html-Graph Service"                          ,
                              version  = "v1.0.0"                                       ,
                              docs_url = "/docs"                                        )
        self.service = Html_Graph__Service()
        self.setup_middleware()
        self.setup_routes()
    
    def setup_middleware(self):
        """Configure CORS and other middleware"""
        self.app.add_middleware(CORSMiddleware                                          ,
                               allow_origins     = ["*"]                                ,
                               allow_credentials = True                                 ,
                               allow_methods     = ["*"]                                ,
                               allow_headers     = ["*"]                                )
    
    def setup_routes(self):
        """Register all API endpoints"""
        
        @self.app.post("/graph/create", response_model=Schema__Html_Graph__Create_Response)
        async def create_graph(request: Schema__Html_Graph__Create_Request):
            """Create a new multi-layer HTML graph"""
            try:
                response = self.service.create_graph(request)
                return response
            except Exception as e:
                raise HTTPException(status_code = 500                                   ,
                                   detail      = f"Graph creation failed: {str(e)}"     )
        
        @self.app.post("/graph/{graph_id}/analyze")
        async def analyze_graph(graph_id : str                                          ,
                               request  : Schema__Html_Graph__Analyze_Request           ):
            """Analyze graph and generate clusters for classification"""
            try:
                response = self.service.analyze_graph(Obj_Id(graph_id), request)
                return response
            except Exception as e:
                raise HTTPException(status_code = 500                                   ,
                                   detail      = f"Analysis failed: {str(e)}"           )
        
        @self.app.post("/graph/{graph_id}/apply-transforms")
        async def apply_transforms(graph_id : str                                       ,
                                   request  : Schema__Html_Graph__Transform_Request     ):
            """Apply transformation decisions and propagate to L0"""
            try:
                response = self.service.apply_transforms(Obj_Id(graph_id), request)
                return response
            except Exception as e:
                raise HTTPException(status_code = 500                                   ,
                                   detail      = f"Transform application failed: {str(e)}")
        
        @self.app.get("/graph/{graph_id}/visualize")
        async def visualize_graph(graph_id         : str                                ,
                                 layer            : Optional[int]  = None               ,
                                 format           : str            = "dot"              ,
                                 include_metadata : bool           = True               ,
                                 show_text_preview: bool           = True               ,
                                 max_text_length  : int            = 50                 ):
            """Generate visual representation of graph"""
            try:
                request = Schema__Html_Graph__Visualize_Request(
                    graph_id          = Obj_Id(graph_id)                                ,
                    layer             = Safe_Int(layer) if layer else None              ,
                    format            = Safe_Id(format)                                 ,
                    include_metadata  = include_metadata                                ,
                    show_text_preview = show_text_preview                               ,
                    max_text_length   = Safe_UInt(max_text_length)                      )
                response = self.service.visualize_graph(request)
                return response
            except Exception as e:
                raise HTTPException(status_code = 500                                   ,
                                   detail      = f"Visualization failed: {str(e)}"      )
        
        @self.app.get("/health")
        async def health_check():
            """Service health check"""
            return self.service.health_check()
        
        @self.app.get("/stats")
        async def get_stats():
            """Service statistics"""
            return self.service.get_stats()


# Entry point
def create_app() -> FastAPI:
    """Factory function to create FastAPI app"""
    api = Html_Graph__Api()
    return api.app


app = create_app()
```

### 5.2 Core Service Class

```python
# File: src/html_graph_service/core/Html_Graph__Service.py

from osbot_utils.type_safe.Type_Safe                                                     import Type_Safe
from osbot_utils.type_safe.primitives.domains.identifiers.Obj_Id                        import Obj_Id

from html_graph_service.builders.Html_Graph__Builder                                    import Html_Graph__Builder
from html_graph_service.analysis.Cluster__Analyzer                                      import Cluster__Analyzer
from html_graph_service.transforms.Transform__Propagator                                import Transform__Propagator
from html_graph_service.visualization.Graph__Visualizer                                 import Graph__Visualizer
from html_graph_service.cache.Graph__Cache                                              import Graph__Cache


class Html_Graph__Service(Type_Safe):
    """Core service orchestrating all HTML graph operations"""
    
    builder        : Html_Graph__Builder
    analyzer       : Cluster__Analyzer
    propagator     : Transform__Propagator
    visualizer     : Graph__Visualizer
    cache          : Graph__Cache
    
    def create_graph(self, request: Schema__Html_Graph__Create_Request) -> Schema__Html_Graph__Create_Response:
        """
        Create multi-layer graph from HTML input
        
        Process:
        1. Check cache for existing graph
        2. Build L0 from html_dict
        3. Extract L1 (content-only)
        4. Consolidate to L2 (parent-based)
        5. Optionally build L3+ (section-level)
        6. Apply compression if enabled
        7. Detect patterns if enabled
        8. Cache result
        """
        
        # Generate cache key from input
        cache_key = self.cache.generate_key(request)
        
        # Check cache
        cached_graph = self.cache.get_graph(cache_key)
        if cached_graph:
            return self._create_response_from_cached(cached_graph                       ,
                                                     cache_key                          ,
                                                     cached = True                      )
        
        # Build new graph
        start_time = Timestamp_Now()
        mgraph     = self.builder.build_from_request(request)
        build_time = Timestamp_Now() - start_time
        
        # Generate response
        response = self._create_response_from_graph(mgraph                              ,
                                                    cache_key                           ,
                                                    build_time                          ,
                                                    cached = False                      )
        
        # Cache for future use
        self.cache.store_graph(cache_key                                                ,
                              mgraph                                                    ,
                              ttl = request.cache_ttl                                   )
        
        return response
    
    def analyze_graph(self, graph_id : Obj_Id                                           ,
                            request  : Schema__Html_Graph__Analyze_Request              ) -> Schema__Html_Graph__Analyze_Response:
        """
        Analyze graph structure and generate optimal clusters
        
        Process:
        1. Retrieve graph from cache
        2. Determine optimal classification layer
        3. Extract cluster nodes from that layer
        4. Aggregate text content per cluster
        5. Generate hash mappings
        6. Return cluster list
        """
        
        # Retrieve graph
        mgraph = self.cache.get_graph_by_id(graph_id)
        if not mgraph:
            raise ValueError(f"Graph not found: {graph_id}")
        
        # Analyze
        start_time = Timestamp_Now()
        response   = self.analyzer.analyze_clusters(mgraph, request)
        analysis_time = Timestamp_Now() - start_time
        
        response.analysis_time_ms = Safe_UInt(analysis_time)
        return response
    
    def apply_transforms(self, graph_id : Obj_Id                                        ,
                               request  : Schema__Html_Graph__Transform_Request         ) -> Schema__Html_Graph__Transform_Response:
        """
        Apply cluster transformation decisions and propagate to L0
        
        Process:
        1. Retrieve graph from cache
        2. For each cluster decision:
           a. Navigate to cluster node in graph
           b. Get all child nodes down to L0
           c. Apply transformation to L0 text nodes
        3. Generate updated hash_mapping
        4. Return transformation results
        """
        
        # Retrieve graph
        mgraph = self.cache.get_graph_by_id(graph_id)
        if not mgraph:
            raise ValueError(f"Graph not found: {graph_id}")
        
        # Apply transforms
        start_time = Timestamp_Now()
        response   = self.propagator.apply_transformations(mgraph, request)
        prop_time  = Timestamp_Now() - start_time
        
        response.propagation_time_ms = Safe_UInt(prop_time)
        return response
    
    def visualize_graph(self, request: Schema__Html_Graph__Visualize_Request) -> Schema__Html_Graph__Visualize_Response:
        """Generate visual representation of graph structure"""
        
        # Retrieve graph
        mgraph = self.cache.get_graph_by_id(request.graph_id)
        if not mgraph:
            raise ValueError(f"Graph not found: {request.graph_id}")
        
        # Generate visualization
        start_time = Timestamp_Now()
        response   = self.visualizer.generate_visualization(mgraph, request)
        gen_time   = Timestamp_Now() - start_time
        
        response.generation_time_ms = Safe_UInt(gen_time)
        return response
    
    def health_check(self) -> Schema__Html_Graph__Health_Response:
        """Perform health check of service and dependencies"""
        
        return Schema__Html_Graph__Health_Response(
            version             = Safe_Str__Version("v1.0.0")                           ,
            status              = Safe_Id("healthy")                                    ,
            timestamp           = Timestamp_Now()                                       ,
            mgraph_db_available = True                                                  ,
            cache_available     = self.cache.is_available()                             ,
            active_graphs       = self.cache.count_active_graphs()                      ,
            uptime_seconds      = self.cache.get_uptime_seconds()                       )
    
    def get_stats(self) -> Schema__Html_Graph__Stats_Response:
        """Retrieve service statistics"""
        
        return self.cache.get_statistics()
```

### 5.3 Graph Builder

```python
# File: src/html_graph_service/builders/Html_Graph__Builder.py

from osbot_utils.type_safe.Type_Safe                                                     import Type_Safe
from mgraph_db.mgraph.MGraph                                                             import MGraph

from html_graph_service.schemas.html_nodes.Schema__Html__Node__L0                       import Schema__Html__Node__L0
from html_graph_service.schemas.html_nodes.Schema__Html__Node__L1                       import Schema__Html__Node__L1
from html_graph_service.schemas.html_nodes.Schema__Html__Node__L2                       import Schema__Html__Node__L2


class Html_Graph__Builder(Type_Safe):
    """Builds multi-layer HTML graphs from html_dict"""
    
    def build_from_request(self, request: Schema__Html_Graph__Create_Request) -> MGraph:
        """
        Main entry point for graph construction
        
        Returns:
            MGraph instance with all requested layers built
        """
        
        mgraph = MGraph()
        
        # Step 1: Build L0 (original HTML tree)
        if 0 in request.build_layers:
            self.build_layer_0(mgraph, request.html_dict)
        
        # Step 2: Build L1 (content-only subgraph)
        if 1 in request.build_layers:
            self.build_layer_1(mgraph)
            
            if request.enable_compression:
                self.compress_layer_1(mgraph)
        
        # Step 3: Build L2 (parent-based consolidation)
        if 2 in request.build_layers:
            self.build_layer_2(mgraph)
        
        # Step 4: Build L3+ (section-level aggregation)
        if 3 in request.build_layers:
            self.build_layer_3(mgraph)
        
        return mgraph
    
    def build_layer_0(self, mgraph: MGraph, html_dict: Dict) -> None:
        """
        Build L0: Original HTML tree structure
        
        Process:
        1. Parse html_dict recursively
        2. Create Schema__Html__Node__L0 for each element/text
        3. Create parent-child edges
        4. Store in mgraph
        """
        
        with mgraph.builder() as builder:
            self._recursive_build_l0(builder, html_dict, parent_id=None)
    
    def _recursive_build_l0(self, builder               ,
                                 node_dict             ,
                                 parent_id : Obj_Id    ):
        """Recursively build L0 nodes from html_dict"""
        
        # Create L0 node for current element
        node_data = Schema__Html__Node__L0__Data(
            layer_number     = Safe_Int(0)                                              ,
            original_html_id = Obj_Id()                                                 ,
            node_path        = []                                                       ,
            original_path    = []                                                       ,
            html_element     = Safe_Str__Id(node_dict.get('tag', 'text'))              ,
            element_type     = Safe_Id('element' if 'tag' in node_dict else 'text')    ,
            attributes       = node_dict.get('attributes', {})                          ,
            text_content     = node_dict.get('text', None)                              )
        
        current_node = builder.add_node(node_data, node_type=Schema__Html__Node__L0)
        
        # Process children recursively
        for child in node_dict.get('children', []):
            self._recursive_build_l0(builder, child, current_node.node_id)
    
    def build_layer_1(self, mgraph: MGraph) -> None:
        """
        Build L1: Content-only subgraph
        
        Process:
        1. Query for all text nodes in L0
        2. For each text node, walk upward to root
        3. Create L1 nodes for this path
        4. Link L1 nodes to original L0 nodes
        """
        
        # Get all L0 text nodes
        text_nodes = (mgraph.query()
                           .by_type(Schema__Html__Node__L0)
                           .filter(lambda n: n.node.data.element_type == Safe_Id('text'))
                           .collect())
        
        # Build content-only paths
        for text_node in text_nodes:
            self._build_l1_path(mgraph, text_node)
    
    def _build_l1_path(self, mgraph: MGraph, text_node):
        """Build L1 path from text node to root"""
        
        # Implementation: walk up parent chain, create L1 nodes
        pass  # Full implementation omitted for brevity
    
    def compress_layer_1(self, mgraph: MGraph) -> None:
        """
        Apply compression to L1
        
        Rules:
        1. Collapse redundant parent chains
        2. Remove wrapper elements with single child
        3. Maintain original_id references
        """
        pass  # Full implementation omitted for brevity
    
    def build_layer_2(self, mgraph: MGraph) -> None:
        """
        Build L2: Parent-based consolidation
        
        Process:
        1. Query all L1 parent nodes (non-text)
        2. For each parent:
           a. Aggregate all child text content
           b. Create L2 node with combined text
           c. Link to L1 children
           d. Link to L0 original
        """
        pass  # Full implementation omitted for brevity
    
    def build_layer_3(self, mgraph: MGraph) -> None:
        """
        Build L3: Section-level aggregation
        
        Process:
        1. Query L2 nodes
        2. Group by structural parent (section, article, div.container)
        3. Create L3 nodes aggregating L2 content
        """
        pass  # Full implementation omitted for brevity
```

### 5.4 Cluster Analyzer

```python
# File: src/html_graph_service/analysis/Cluster__Analyzer.py

from osbot_utils.type_safe.Type_Safe                                                     import Type_Safe
from mgraph_db.mgraph.MGraph                                                             import MGraph


class Cluster__Analyzer(Type_Safe):
    """Analyzes graph structure to generate optimal classification clusters"""
    
    def analyze_clusters(self, mgraph  : MGraph                                         ,
                               request : Schema__Html_Graph__Analyze_Request            ) -> Schema__Html_Graph__Analyze_Response:
        """
        Main analysis entry point
        
        Process:
        1. Determine optimal layer based on content_type and mode
        2. Extract nodes from that layer
        3. Generate cluster objects with aggregated text
        4. Return analysis results
        """
        
        # Determine optimal layer
        recommended_layer = self._determine_optimal_layer(mgraph                        ,
                                                          request.content_type          ,
                                                          request.preferred_layer       )
        
        # Extract clusters from that layer
        clusters = self._extract_clusters_from_layer(mgraph                             ,
                                                     recommended_layer                  ,
                                                     request                            )
        
        # Generate response
        total_text = sum(len(c.aggregated_text) for c in clusters)
        
        return Schema__Html_Graph__Analyze_Response(
            graph_id          = request.graph_id                                        ,
            recommended_layer = recommended_layer                                       ,
            clusters          = clusters                                                ,
            total_clusters    = Safe_UInt(len(clusters))                                ,
            total_text_length = Safe_UInt(total_text)                                   ,
            analysis_time_ms  = Safe_UInt(0)                                            )  # Set by caller
    
    def _determine_optimal_layer(self, mgraph        : MGraph                           ,
                                       content_type : Safe_Id                           ,
                                       preferred    : Optional[Safe_Int]                ) -> Safe_Int:
        """
        Determine which layer is optimal for classification
        
        Rules:
        - Article content: L2 (paragraph-level)
        - List content: L2 (list-item-level)
        - Mixed content: L3 (section-level)
        - User preference overrides if specified
        """
        
        if preferred is not None:
            return preferred
        
        if content_type == Safe_Id("article"):
            return Safe_Int(2)
        elif content_type == Safe_Id("list"):
            return Safe_Int(2)
        elif content_type == Safe_Id("mixed"):
            return Safe_Int(3)
        else:
            return Safe_Int(2)  # Default to L2
    
    def _extract_clusters_from_layer(self, mgraph : MGraph                              ,
                                            layer  : Safe_Int                            ,
                                            request: Schema__Html_Graph__Analyze_Request ) -> List[Schema__Html_Graph__Cluster_Node]:
        """Extract cluster nodes from specified layer"""
        
        clusters = []
        
        # Query nodes at target layer
        layer_nodes = (mgraph.query()
                            .filter(lambda n: n.node.data.layer_number == layer)
                            .collect())
        
        for node in layer_nodes:
            # Skip if text too short
            if len(node.node.data.aggregated_text) < request.min_text_length:
                continue
            
            # Create cluster
            cluster = Schema__Html_Graph__Cluster_Node(
                cluster_id        = Obj_Id()                                            ,
                layer_number      = layer                                               ,
                graph_node_id     = node.node_id                                        ,
                aggregated_text   = Safe_Str__Text(node.node.data.aggregated_text)     ,
                text_hash         = Safe_Str__Hash(self._hash_text(node.node.data.aggregated_text)),
                hash_references   = self._get_hash_references(mgraph, node)            ,
                l0_node_ids       = self._get_l0_node_ids(mgraph, node)                ,
                pattern_type      = node.node.data.pattern_type                        ,
                child_cluster_ids = []                                                  ,
                metadata          = {}                                                  )
            
            clusters.append(cluster)
            
            # Limit to max_clusters
            if len(clusters) >= request.max_clusters:
                break
        
        return clusters
    
    def _hash_text(self, text: str) -> str:
        """Generate hash for text content"""
        import hashlib
        return hashlib.md5(text.encode()).hexdigest()[:10]
    
    def _get_hash_references(self, mgraph: MGraph, node) -> List[Safe_Str__Hash]:
        """Get all text hashes from original HTML Service"""
        # Navigate down to L0 text nodes and collect their hashes
        pass  # Full implementation omitted
    
    def _get_l0_node_ids(self, mgraph: MGraph, node) -> List[Obj_Id]:
        """Get all L0 node IDs that this cluster encompasses"""
        # Navigate down to L0 and collect node IDs
        pass  # Full implementation omitted
```

---

## 6. Integration with Mitmproxy Pipeline

### 6.1 Enhanced Pipeline Flow

```
┌─────────────────────────────────────────────────────────────────┐
│              Enhanced Mitmproxy Transformation Pipeline         │
└─────────────────────────────────────────────────────────────────┘

Browser Request
    │
    ▼
[Mitmproxy Intercepts]
    │
    ▼
[FastAPI Proxy Handler]
    │
    ├─→ Forward to Upstream Server
    │   └─→ Receive HTML Response
    │
    ▼
┌─────────────────────────────────────────────────────────────────┐
│ STEP 1: HTML Parsing                                            │
│ ┌─────────────────────────────────────────────────────────────┐ │
│ │ HTML Service: POST /html/to/dict/hashes                     │ │
│ │ Input:  Raw HTML                                            │ │
│ │ Output: html_dict + hash_mapping                            │ │
│ └─────────────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────────────────────────────────┐
│ STEP 2: Graph Construction                        [NEW]        │
│ ┌─────────────────────────────────────────────────────────────┐ │
│ │ Html-Graph Service: POST /graph/create                      │ │
│ │ Input:  html_dict + hash_mapping                            │ │
│ │ Output: graph_id + layer_stats                              │ │
│ │ Builds: L0 → L1 → L2 → L3                                   │ │
│ └─────────────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────────────────────────────────┐
│ STEP 3: Cluster Analysis                          [NEW]        │
│ ┌─────────────────────────────────────────────────────────────┐ │
│ │ Html-Graph Service: POST /graph/{id}/analyze                │ │
│ │ Input:  classification_mode, content_type                   │ │
│ │ Output: recommended_layer, clusters[]                       │ │
│ │ Logic:  Determines optimal level (L2 vs L3)                 │ │
│ │         Extracts meaningful semantic units                  │ │
│ └─────────────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────────────────────────────────┐
│ STEP 4: Semantic Classification                   [EXISTING]   │
│ ┌─────────────────────────────────────────────────────────────┐ │
│ │ Semantic Text Service: POST /text-transformation/transform  │ │
│ │ Input:  cluster texts (aggregated)                          │ │
│ │ Output: sentiment per cluster                               │ │
│ │ Note:   Classifies at cluster level, not text level         │ │
│ └─────────────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────────────────────────────────┐
│ STEP 5: Transform Decision & Propagation          [NEW]        │
│ ┌─────────────────────────────────────────────────────────────┐ │
│ │ Html-Graph Service: POST /graph/{id}/apply-transforms       │ │
│ │ Input:  cluster_decisions[]                                 │ │
│ │ Output: transformed_hash_mapping                            │ │
│ │ Logic:  Propagates cluster decisions → L2 → L1 → L0         │ │
│ │         Generates updated text for each hash                │ │
│ └─────────────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────────────────────────────────┐
│ STEP 6: HTML Reconstruction                       [EXISTING]   │
│ ┌─────────────────────────────────────────────────────────────┐ │
│ │ HTML Service: POST /hashes/to/html                          │ │
│ │ Input:  html_dict + transformed_hash_mapping                │ │
│ │ Output: Transformed HTML                                    │ │
│ └─────────────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────────┘
    │
    ▼
[Return to Browser]
```

### 6.2 Proxy Handler Integration

```python
# File: mitmproxy_service/handlers/enhanced_response_handler.py

from html_graph_service.client.Html_Graph__Client                                       import Html_Graph__Client


class Enhanced_Response_Handler(Type_Safe):
    """Enhanced response handler with Html-Graph integration"""
    
    html_service     : Html_Service__Client
    semantic_service : Semantic_Text__Client
    graph_service    : Html_Graph__Client           # NEW
    cache_service    : Cache__Client
    
    async def process_html_response(self, html      : Safe_Str__Html                    ,
                                          mitm_mode : Safe_Id                            ) -> Safe_Str__Html:
        """
        Process HTML with graph-based transformation
        
        Returns:
            Transformed HTML
        """
        
        # STEP 1: Parse HTML (existing)
        html_result = await self.html_service.html_to_dict_hashes(html)
        html_dict   = html_result.html_dict
        hash_mapping = html_result.hash_mapping
        
        # STEP 2: Build graph (NEW)
        graph_request = Schema__Html_Graph__Create_Request(
            html_dict              = html_dict                                          ,
            hash_mapping           = hash_mapping                                       ,
            build_layers           = [0, 1, 2, 3]                                       ,
            enable_compression     = True                                               ,
            enable_pattern_detection = False                                            )
        
        graph_response = await self.graph_service.create_graph(graph_request)
        graph_id = graph_response.graph_id
        
        # STEP 3: Analyze clusters (NEW)
        analyze_request = Schema__Html_Graph__Analyze_Request(
            graph_id           = graph_id                                               ,
            classification_mode = mitm_mode                                             ,
            content_type       = Safe_Id("article")                                    ,
            min_text_length    = Safe_UInt(10)                                          ,
            max_clusters       = Safe_UInt(100)                                         )
        
        analyze_response = await self.graph_service.analyze_graph(analyze_request)
        clusters = analyze_response.clusters
        
        # STEP 4: Classify at cluster level (existing service, new usage)
        cluster_texts = {c.cluster_id: c.aggregated_text for c in clusters}
        
        classification_result = await self.semantic_service.classify_texts(
            texts              = cluster_texts                                          ,
            engine_mode        = "AWS_COMPREHEND"                                       ,
            criterion_filters  = self._parse_filters_from_mode(mitm_mode)              )
        
        # STEP 5: Make transform decisions
        cluster_decisions = []
        for cluster in clusters:
            sentiment = classification_result.get(cluster.cluster_id)
            
            if self._should_transform(sentiment, mitm_mode):
                transformed_text = self._apply_transformation(cluster.aggregated_text   ,
                                                              mitm_mode                 )
                decision = Schema__Html_Graph__Transform_Decision(
                    cluster_id         = cluster.cluster_id                             ,
                    action             = Safe_Id("transform")                           ,
                    transformation_mode = Safe_Id("xxx")                                ,
                    transformed_text   = Safe_Str__Text(transformed_text)               ,
                    metadata           = {"sentiment": sentiment}                       )
            else:
                decision = Schema__Html_Graph__Transform_Decision(
                    cluster_id         = cluster.cluster_id                             ,
                    action             = Safe_Id("keep")                                ,
                    transformation_mode = None                                          ,
                    transformed_text   = None                                           ,
                    metadata           = {}                                             )
            
            cluster_decisions.append(decision)
        
        # STEP 5: Apply transforms and propagate (NEW)
        transform_request = Schema__Html_Graph__Transform_Request(
            graph_id         = graph_id                                                 ,
            cluster_decisions = cluster_decisions                                       ,
            propagation_mode = Safe_Id("standard")                                      )
        
        transform_response = await self.graph_service.apply_transforms(transform_request)
        transformed_hash_mapping = transform_response.transformed_hash_mapping
        
        # STEP 6: Reconstruct HTML (existing)
        final_html = await self.html_service.hashes_to_html(html_dict                  ,
                                                            transformed_hash_mapping    )
        
        return final_html
```

---

## 7. MGraphDB Integration

### 7.1 HTML-Specific Node Schemas

```python
# File: src/html_graph_service/schemas/html_nodes/Schema__Html__Node__Base.py

from mgraph_db.mgraph.schemas.Schema__MGraph__Node                                       import Schema__MGraph__Node
from mgraph_db.mgraph.schemas.Schema__MGraph__Node__Data                                 import Schema__MGraph__Node__Data


class Schema__Html__Node__Base__Data(Schema__MGraph__Node__Data):
    """Base data schema for all HTML graph nodes"""
    
    layer_number     : Safe_Int                                     # Which layer (0, 1, 2, 3)
    original_html_id : Obj_Id                                       # Reference to L0 node
    node_path        : List[Obj_Id]                                # Path to root in current layer
    original_path    : List[Obj_Id]                                # Full path in L0
    html_element     : Optional[Safe_Id]         = None            # HTML tag name


class Schema__Html__Node__Base(Schema__MGraph__Node):
    """Base node schema for all HTML graph nodes"""
    
    node_data: Schema__Html__Node__Base__Data
```

```python
# File: src/html_graph_service/schemas/html_nodes/Schema__Html__Node__L0.py

class Schema__Html__Node__L0__Data(Schema__Html__Node__Base__Data):
    """L0: Original HTML node data"""
    
    element_type     : Safe_Id                                      # 'element', 'text', 'comment'
    attributes       : Dict[Safe_Id, Safe_Str__Text]               # HTML attributes
    text_content     : Optional[Safe_Str__Text]      = None        # For text nodes


class Schema__Html__Node__L0(Schema__Html__Node__Base):
    """L0: Original HTML node"""
    
    node_data: Schema__Html__Node__L0__Data
```

```python
# File: src/html_graph_service/schemas/html_nodes/Schema__Html__Node__L1.py

class Schema__Html__Node__L1__Data(Schema__Html__Node__Base__Data):
    """L1: Content-only node data"""
    
    compression_info : Optional[Dict[Safe_Id, str]]  = None        # Compression metadata
    l0_references    : List[Obj_Id]                                # All L0 nodes represented


class Schema__Html__Node__L1(Schema__Html__Node__Base):
    """L1: Content-only node"""
    
    node_data: Schema__Html__Node__L1__Data
```

```python
# File: src/html_graph_service/schemas/html_nodes/Schema__Html__Node__L2.py

class Schema__Html__Node__L2__Data(Schema__Html__Node__Base__Data):
    """L2: Consolidated node data"""
    
    aggregated_text  : Safe_Str__Text                              # Combined text content
    l1_references    : List[Obj_Id]                                # L1 nodes aggregated
    text_hash        : Optional[Safe_Str__Hash]      = None        # Hash for semantic service


class Schema__Html__Node__L2(Schema__Html__Node__Base):
    """L2: Consolidated node"""
    
    node_data: Schema__Html__Node__L2__Data
```

```python
# File: src/html_graph_service/schemas/html_nodes/Schema__Html__Node__L3.py

class Schema__Html__Node__L3__Data(Schema__Html__Node__Base__Data):
    """L3: Section-level node data"""
    
    aggregated_text  : Safe_Str__Text                              # Combined section text
    l2_references    : List[Obj_Id]                                # L2 nodes aggregated
    pattern_type     : Optional[Safe_Id]             = None        # Recognized pattern
    semantic_summary : Optional[Safe_Str__Text]      = None        # AI-generated summary


class Schema__Html__Node__L3(Schema__Html__Node__Base):
    """L3: Section-level node"""
    
    node_data: Schema__Html__Node__L3__Data
```

### 7.2 HTML-Specific Edge Schemas

```python
# File: src/html_graph_service/schemas/html_edges/Schema__Html__Edge__Parent.py

from mgraph_db.mgraph.schemas.Schema__MGraph__Edge                                       import Schema__MGraph__Edge


class Schema__Html__Edge__Parent(Schema__MGraph__Edge):
    """Standard parent-child edge within a layer"""
    pass
```

```python
# File: src/html_graph_service/schemas/html_edges/Schema__Html__Edge__Aggregates.py

class Schema__Html__Edge__Aggregates__Data(Schema__MGraph__Edge__Data):
    """Data for aggregation edges"""
    
    aggregation_type : Safe_Id                                     # 'parent_based', 'semantic', 'pattern'
    weight           : Safe_Float__Percentage_Exact                # Aggregation strength


class Schema__Html__Edge__Aggregates(Schema__MGraph__Edge):
    """Edge from higher layer node to lower layer nodes it aggregates"""
    
    edge_data: Schema__Html__Edge__Aggregates__Data
```

```python
# File: src/html_graph_service/schemas/html_edges/Schema__Html__Edge__Original_Reference.py

class Schema__Html__Edge__Original_Reference__Data(Schema__MGraph__Edge__Data):
    """Data for original reference edges"""
    
    layer_distance  : Safe_Int                                     # Layers between nodes
    preservation    : bool                                         # Preserve during transforms


class Schema__Html__Edge__Original_Reference(Schema__MGraph__Edge):
    """Edge from any layer node back to L0 original"""
    
    edge_data: Schema__Html__Edge__Original_Reference__Data
```

---

## 8. Performance & Caching

### 8.1 Cache Strategy

```python
# File: src/html_graph_service/cache/Graph__Cache.py

class Graph__Cache(Type_Safe):
    """Manages graph caching with Redis backend"""
    
    cache_service : Cache__Client
    prefix        : Safe_Id                          = "html-graph:"
    default_ttl   : Safe_UInt                        = 3600          # 1 hour
    
    def generate_key(self, request: Schema__Html_Graph__Create_Request) -> Safe_Str__Hash:
        """
        Generate deterministic cache key from request
        
        Key includes:
        - Hash of html_dict structure
        - Requested layers
        - Compression settings
        - Pattern detection settings
        """
        
        import hashlib
        import json
        
        key_components = {
            'html_dict'       : json.dumps(request.html_dict, sort_keys=True)          ,
            'layers'          : request.build_layers                                   ,
            'compression'     : request.enable_compression                             ,
            'pattern_detection': request.enable_pattern_detection                      }
        
        key_str = json.dumps(key_components, sort_keys=True)
        hash_value = hashlib.md5(key_str.encode()).hexdigest()[:10]
        
        return Safe_Str__Hash(hash_value)
    
    def store_graph(self, cache_key : Safe_Str__Hash                                    ,
                          mgraph    : MGraph                                            ,
                          ttl       : Safe_UInt                                         ) -> bool:
        """Store graph in cache with TTL"""
        
        # Serialize graph to JSON
        graph_json = mgraph.export().to_json()
        
        # Store in cache
        full_key = f"{self.prefix}{cache_key}"
        return self.cache_service.set(full_key                                          ,
                                     graph_json                                         ,
                                     ttl = ttl                                          )
    
    def get_graph(self, cache_key: Safe_Str__Hash) -> Optional[MGraph]:
        """Retrieve graph from cache"""
        
        full_key = f"{self.prefix}{cache_key}"
        graph_json = self.cache_service.get(full_key)
        
        if graph_json:
            # Deserialize and reconstruct MGraph
            mgraph = MGraph()
            mgraph.import_json(graph_json)
            return mgraph
        
        return None
    
    def get_graph_by_id(self, graph_id: Obj_Id) -> Optional[MGraph]:
        """Retrieve graph by its ID"""
        
        # Search cache for graph with this ID
        # Implementation depends on cache backend capabilities
        pass
```

### 8.2 Performance Optimizations

```python
# File: src/html_graph_service/core/Performance__Monitor.py

class Performance__Monitor(Type_Safe):
    """Monitors and optimizes service performance"""
    
    stats : Dict[Safe_Id, Safe_UInt]
    
    def record_build_time(self, graph_id : Obj_Id                                       ,
                                build_time: Safe_UInt                                   ) -> None:
        """Record graph build time for metrics"""
        
        key = Safe_Id("build_time_total")
        self.stats[key] = self.stats.get(key, Safe_UInt(0)) + build_time
    
    def get_average_build_time(self) -> Safe_UInt:
        """Calculate average build time"""
        
        total = self.stats.get(Safe_Id("build_time_total"), Safe_UInt(0))
        count = self.stats.get(Safe_Id("build_count"), Safe_UInt(1))
        
        return Safe_UInt(total / count)
```

---

## 9. Testing Strategy

### 9.1 Unit Tests

```python
# File: tests/unit/test_graph_builder.py

import pytest
from html_graph_service.builders.Html_Graph__Builder                                    import Html_Graph__Builder


class Test__Html_Graph__Builder:
    """Unit tests for graph builder"""
    
    def test__build_layer_0__simple_html(self):
        """Test L0 construction from simple HTML"""
        
        html_dict = {
            'tag': 'div'                                                                ,
            'children': [
                {'tag': 'p', 'children': [{'text': 'Hello'}]}                          ]}
        
        builder = Html_Graph__Builder()
        request = Schema__Html_Graph__Create_Request(
            html_dict    = html_dict                                                    ,
            build_layers = [0]                                                          )
        
        mgraph = builder.build_from_request(request)
        
        assert mgraph.data().nodes_count() == 3  # div, p, text
        assert mgraph.data().edges_count() == 2  # div→p, p→text
    
    def test__build_layer_1__content_only(self):
        """Test L1 content-only extraction"""
        
        # Test with empty divs that should be removed
        html_dict = {
            'tag': 'div'                                                                ,
            'children': [
                {'tag': 'div', 'children': []},  # Empty - should be removed           
                {'tag': 'p', 'children': [{'text': 'Content'}]}                        ]}
        
        builder = Html_Graph__Builder()
        request = Schema__Html_Graph__Create_Request(
            html_dict    = html_dict                                                    ,
            build_layers = [0, 1]                                                       )
        
        mgraph = builder.build_from_request(request)
        
        l1_nodes = (mgraph.query()
                         .filter(lambda n: n.node.data.layer_number == Safe_Int(1))
                         .collect())
        
        # L1 should only have nodes in path to text
        assert len(l1_nodes) == 3  # div, p, text (empty div removed)
```

### 9.2 Integration Tests

```python
# File: tests/integration/test_full_pipeline.py

class Test__Full_Pipeline:
    """Integration tests for complete pipeline"""
    
    @pytest.mark.asyncio
    async def test__end_to_end__simple_article(self):
        """Test complete flow from HTML to transformed output"""
        
        # Setup
        html_input = """
        <article>
            <h1>Product Review</h1>
            <p>This <b>amazing</b> product works well.</p>
            <p>However, the service was <span>terrible</span>.</p>
        </article>
        """
        
        service = Html_Graph__Service()
        
        # Step 1: Create graph
        create_request = Schema__Html_Graph__Create_Request(
            html             = Safe_Str__Html(html_input)                               ,
            build_layers     = [0, 1, 2]                                                ,
            enable_compression = True                                                   )
        
        create_response = await service.create_graph(create_request)
        graph_id = create_response.graph_id
        
        # Step 2: Analyze
        analyze_request = Schema__Html_Graph__Analyze_Request(
            graph_id           = graph_id                                               ,
            classification_mode = Safe_Id("xxx-negative")                               ,
            content_type       = Safe_Id("article")                                     )
        
        analyze_response = await service.analyze_graph(graph_id, analyze_request)
        
        assert analyze_response.recommended_layer == Safe_Int(2)
        assert analyze_response.total_clusters >= 2  # At least 2 paragraphs
        
        # Step 3: Apply mock transformations
        decisions = [
            Schema__Html_Graph__Transform_Decision(
                cluster_id         = analyze_response.clusters[0].cluster_id            ,
                action             = Safe_Id("keep")                                    ,
                transformation_mode = None                                              ,
                transformed_text   = None                                               ,
                metadata           = {}                                                 ),
            Schema__Html_Graph__Transform_Decision(
                cluster_id         = analyze_response.clusters[1].cluster_id            ,
                action             = Safe_Id("transform")                               ,
                transformation_mode = Safe_Id("xxx")                                    ,
                transformed_text   = Safe_Str__Text("xxxxxxx, xxx xxxxxxx xxx xxxxxxxx."),
                metadata           = {}                                                 )]
        
        transform_request = Schema__Html_Graph__Transform_Request(
            graph_id         = graph_id                                                 ,
            cluster_decisions = decisions                                               ,
            propagation_mode = Safe_Id("standard")                                      )
        
        transform_response = await service.apply_transforms(graph_id, transform_request)
        
        assert transform_response.clusters_transformed == Safe_UInt(1)
        assert len(transform_response.transformed_hash_mapping) > 0
```

---

## 10. Deployment Configuration

### 10.1 Docker Configuration

```dockerfile
# File: Dockerfile

FROM python:3.11-slim

WORKDIR /app

# Install dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application
COPY src/ ./src/
COPY tests/ ./tests/

# Environment variables
ENV PYTHONPATH=/app/src
ENV SERVICE_PORT=8000
ENV SERVICE_HOST=0.0.0.0

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:8000/health || exit 1

# Run application
CMD ["uvicorn", "html_graph_service.api.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### 10.2 Requirements

```text
# File: requirements.txt

# Core Framework
fastapi==0.104.1
uvicorn[standard]==0.24.0
pydantic==2.5.0

# OSBot-Utils & MGraphDB
osbot-utils==3.28.0
mgraph-db==1.2.18

# HTTP Client
httpx==0.25.2
aiohttp==3.9.1

# Caching
redis==5.0.1
hiredis==2.2.3

# Utilities
python-multipart==0.0.6
python-dotenv==1.0.0

# Testing
pytest==7.4.3
pytest-asyncio==0.21.1
pytest-cov==4.1.0
```

### 10.3 Environment Variables

```bash
# File: .env.example

# Service Configuration
SERVICE_NAME=html-graph-service
SERVICE_VERSION=v1.0.0
SERVICE_PORT=8000
SERVICE_HOST=0.0.0.0

# External Services
HTML_SERVICE_URL=https://html.dev.mgraph.ai
CACHE_SERVICE_URL=https://cache.dev.mgraph.ai

# Redis Configuration (for local cache)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=

# Performance
MAX_GRAPH_SIZE=10000
MAX_CACHE_GRAPHS=1000
DEFAULT_CACHE_TTL=3600

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json
```

### 10.4 Kubernetes Deployment

```yaml
# File: k8s/deployment.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: html-graph-service
  namespace: mgraph-services
spec:
  replicas: 3
  selector:
    matchLabels:
      app: html-graph-service
  template:
    metadata:
      labels:
        app: html-graph-service
    spec:
      containers:
      - name: html-graph-service
        image: mgraph/html-graph-service:v1.0.0
        ports:
        - containerPort: 8000
        env:
        - name: SERVICE_PORT
          value: "8000"
        - name: CACHE_SERVICE_URL
          value: "http://cache-service:8000"
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "2000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: html-graph-service
  namespace: mgraph-services
spec:
  selector:
    app: html-graph-service
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000
  type: LoadBalancer
```

---

## 11. Implementation Checklist

### Phase 1: Core Infrastructure (Week 1)
- [ ] Create project structure with proper Type_Safe imports
- [ ] Implement base schemas (Create/Analyze/Transform request/response)
- [ ] Build FastAPI application skeleton with health endpoint
- [ ] Implement Graph__Cache with Redis backend
- [ ] Set up unit test framework
- [ ] Create Docker configuration

### Phase 2: Graph Construction (Week 2)
- [ ] Implement Html_Graph__Builder.build_layer_0()
- [ ] Implement Html_Graph__Builder.build_layer_1()
- [ ] Implement L1 compression logic
- [ ] Implement Html_Graph__Builder.build_layer_2()
- [ ] Implement Html_Graph__Builder.build_layer_3()
- [ ] Unit tests for each layer
- [ ] Integration test for full graph construction

### Phase 3: Analysis Engine (Week 3)
- [ ] Implement Cluster__Analyzer.analyze_clusters()
- [ ] Implement layer selection logic
- [ ] Implement cluster extraction from layer
- [ ] Implement hash reference collection
- [ ] Implement L0 node ID traversal
- [ ] Unit tests for analysis
- [ ] Integration test with graph builder

### Phase 4: Transform Propagation (Week 4)
- [ ] Implement Transform__Propagator.apply_transformations()
- [ ] Implement L3→L2→L1→L0 propagation logic
- [ ] Implement hash_mapping generation
- [ ] Unit tests for propagation
- [ ] Integration test for full pipeline

### Phase 5: Visualization (Week 5)
- [ ] Implement Graph__Visualizer.generate_dot()
- [ ] Implement JSON export
- [ ] Implement SVG generation (optional)
- [ ] Add layer filtering
- [ ] Unit tests for visualization

### Phase 6: Pattern Recognition (Week 6)
- [ ] Implement Pattern__Recognizer.detect_patterns()
- [ ] Add paragraph-block pattern
- [ ] Add bullet-list pattern
- [ ] Add card pattern
- [ ] Unit tests for patterns

### Phase 7: Integration & Testing (Week 7)
- [ ] Integration tests with HTML Service
- [ ] Integration tests with Cache Service
- [ ] Performance testing and optimization
- [ ] Load testing
- [ ] Memory profiling

### Phase 8: Production Readiness (Week 8)
- [ ] Complete documentation
- [ ] API examples
- [ ] Deployment guides
- [ ] Monitoring setup
- [ ] Production deployment

---

## 12. Critical Implementation Notes

### 12.1 Type_Safe Best Practices

```python
# ✓ CORRECT - Always use Safe_* types
class MySchema(Type_Safe):
    node_id  : Obj_Id                               # NOT str
    count    : Safe_UInt                            # NOT int
    text     : Safe_Str__Text                       # NOT str
    metadata : Dict[Safe_Id, Safe_Str__Text]       # Typed dict

# ✗ WRONG - Never use raw primitives
class MySchema(Type_Safe):
    node_id  : str                                  # WRONG
    count    : int                                  # WRONG
    text     : str                                  # WRONG
    metadata : dict                                 # WRONG
```

### 12.2 Method Formatting

```python
# ✓ CORRECT - Vertical alignment for multi-parameter methods
def create_graph(self, html_dict    : Dict                                              ,
                       hash_mapping : Dict[Safe_Str__Hash, Safe_Str__Text]              ,
                       build_layers : List[Safe_Int]                                    ,
                       enable_compression: bool                                         ) -> Schema__Html_Graph__Create_Response:
    pass

# ✗ WRONG - PEP-8 style
def create_graph(
    self,
    html_dict,
    hash_mapping,
    build_layers,
    enable_compression
):
    pass
```

### 12.3 MGraphDB Integration

```python
# ✓ CORRECT - Use mGraphDB builder pattern
with mgraph.builder() as builder:
    builder.add_node(node_data, node_type=Schema__Html__Node__L0)
           .add_connected_node(child_data, edge_type=Schema__Html__Edge__Parent)
           .up()
           .add_connected_node(sibling_data)

# ✗ WRONG - Direct model manipulation
mgraph.data().graph.model.add_node(node)  # Bypasses index updates
```

---

## 13. Support & Maintenance

### 13.1 Logging Strategy

```python
import logging

logger = logging.getLogger("html_graph_service")

# Log at appropriate levels
logger.info(f"Building graph for {len(html_dict)} nodes")
logger.warning(f"Large graph detected: {node_count} nodes")
logger.error(f"Graph construction failed: {error}")
logger.debug(f"L1 compression reduced nodes by {compression_ratio}%")
```

### 13.2 Error Handling

```python
# Use specific exception types
class GraphConstructionError(Exception):
    """Raised when graph construction fails"""
    pass

class ClusterAnalysisError(Exception):
    """Raised when cluster analysis fails"""
    pass

# Wrap external calls
try:
    html_result = await html_service.parse(html)
except Exception as e:
    logger.error(f"HTML parsing failed: {e}")
    raise GraphConstructionError(f"Failed to parse HTML: {e}")
```

---

**End of Technical Briefing**

This document provides complete specifications for implementing the Html-Graph Service with proper Type_Safe patterns, mGraphDB integration, and alignment with the existing mitmproxy pipeline. All schemas use Safe_* primitives and follow the prescribed formatting guidelines.
